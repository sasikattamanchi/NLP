{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f4e7b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa825695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30742823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d97c8c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdf2c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17d13609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "966ef835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28081bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37235461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1faeec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9914b4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35e4f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8608101b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8520f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "305247e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58506b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f90444ccaf0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(8912323)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26bb82ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97cd5eb",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------\n",
    "\n",
    "-------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc981d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_contextword_pairs(sentence, window_size=5): \n",
    "    all_word_context_pairs = []\n",
    "    \n",
    "    for i, word in enumerate(sentence):\n",
    "#         win_size = np.random.randint(low = 1, high = window_size+1 )\n",
    "        win_size = window_size\n",
    "        contexts = sentence[i-win_size:i] + sentence[i+1:i+win_size+1]\n",
    "        all_word_context_pairs.append([(word, context_word) for context_word in contexts])\n",
    "    return list(chain.from_iterable(all_word_context_pairs))\n",
    "\n",
    "def generate_word_contextword_pairs_dynamic(sentence, window_size=5): \n",
    "    # window size is dynamic. window_size parameter is the maximum allowed window_size.\n",
    "    # so for each word, win_size is uniformly sampled from [1, window_size]\n",
    "    # Ref: Goldberg and Levy 2014 \n",
    "\n",
    "    all_word_context_pairs = []\n",
    "    \n",
    "    for i, word in enumerate(sentence):\n",
    "        win_size = np.random.randint(low = 1, high = window_size+1 )\n",
    "#         win_size = window_size\n",
    "        contexts = sentence[i-win_size:i] + sentence[i+1:i+win_size+1]\n",
    "        all_word_context_pairs.append([(word, context_word) for context_word in contexts])\n",
    "    return list(chain.from_iterable(all_word_context_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7242d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = torch.load('teWikiCorpus.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b6c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44713a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_freq = Counter(list(chain.from_iterable(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "355cb835",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_w = list(unigram_freq.keys())\n",
    "vocab_w.insert(0, '<unk>')\n",
    "vocab_w_size = len(vocab_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1875fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9936d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate character ngrams for each word\n",
    "# Ref: page 3 of  Enriching Word Vectors with Subword Information\n",
    "# https://arxiv.org/pdf/1607.04606.pdf\n",
    "\n",
    "# with hash\n",
    "def extract_ngrams(str, n1, n2=None):\n",
    "    if n2 is None:\n",
    "        nv= [n1]\n",
    "    else:\n",
    "        nv = np.arange(n1, n2)\n",
    "\n",
    "    str = '<'+str+'>'\n",
    "    n_grams =[]\n",
    "    for n in nv:\n",
    "        for i in np.arange(len(str)-n+1):\n",
    "            n_grams.append(hash(str[i:i+n]))\n",
    "    n_grams.append(hash(str))\n",
    "    return list(set(n_grams))\n",
    "\n",
    "# without hash\n",
    "def extract_ngrams_nohash(str, n1, n2=None):\n",
    "    if n2 is None:\n",
    "        nv= [n1]\n",
    "    else:\n",
    "        nv = np.arange(n1, n2)\n",
    "\n",
    "    str = '<'+str+'>'\n",
    "    n_grams =[]\n",
    "    for n in nv:\n",
    "        for i in np.arange(len(str)-n+1):\n",
    "            n_grams.append(str[i:i+n])\n",
    "    n_grams.append(str)\n",
    "    return list(set(n_grams))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "507c9ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_ngrams_nohash('విస్తీర్ణంలో', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e23a2d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_ngrams_dict = {}\n",
    "for word in vocab_w:\n",
    "    char_ngrams_dict.update({word:extract_ngrams(word,3,7)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86e337e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_ngrams_dict['రెండవ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ceb9ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(chain.from_iterable(char_ngrams_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a5544f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size  = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79d50ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_freq = torch.Tensor(list(unigram_freq.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1c2c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_freq = vocab_freq/vocab_freq.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c33f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_dist = vocab_freq**0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b602b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_dist = sampling_dist/sampling_dist.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4665d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = {word: i for i, word in enumerate(vocab_w)}\n",
    "indx_to_word = {i: word for i, word in enumerate(vocab_w)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc3a3860",
   "metadata": {},
   "outputs": [],
   "source": [
    "subword_to_idx = {word: i for i, word in enumerate(vocab)}\n",
    "indx_to_subword = {i: word for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7060085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indx_to_char=[]\n",
    "for i in range(len(indx_to_word)):\n",
    "#     word_indx_to_char.append(torch.IntTensor([subword_to_idx[subword] for subword in char_ngrams_dict[indx_to_word[i]]]).long())\n",
    "    word_indx_to_char.append([subword_to_idx[subword] for subword in char_ngrams_dict[indx_to_word[i]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23553b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[45869]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_indx_to_char[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3706eecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_word_contextword_pairs generate_word_contextword_pairs(sentence, n_of_ngram=3):\n",
    "#     n = n_of_ngram\n",
    "#     indx = int((n_of_ngram-1)/2)\n",
    "#     all_word_context_pairs = []\n",
    "#     for i in np.arange(len(sentence)-n + 1):\n",
    "#         all_word_context_pairs.append([(sentence[i+indx], context_word) for context_word in sentence[i:i+indx]])\n",
    "#         all_word_context_pairs.append([(sentence[i+indx], context_word) for context_word in sentence[i+indx+1:i+n]])\n",
    "    \n",
    "#     return list(chain.from_iterable(all_word_context_pairs))\n",
    "\n",
    "# def generate_word_contextword_pairs(sentence, window_size=5): \n",
    "#     all_word_context_pairs = []\n",
    "#     for i in np.arange(window_size, len(sentence)-window_size):\n",
    "#         all_word_context_pairs.append([(sentence[i], context_word) for context_word in sentence[i-window_size:i]])\n",
    "#         all_word_context_pairs.append([(sentence[i], context_word) for context_word in sentence[i+1:i+window_size+1]])\n",
    "    \n",
    "#     return list(chain.from_iterable(all_word_context_pairs))\n",
    "\n",
    "def generate_word_contextword_pairs(sentence, window_size=5): \n",
    "    all_word_context_pairs = []\n",
    "    \n",
    "    for i, word in enumerate(sentence):\n",
    "#         win_size = np.random.randint(low = 1, high = window_size+1 )\n",
    "        win_size = window_size\n",
    "        contexts = sentence[i-win_size:i] + sentence[i+1:i+win_size+1]\n",
    "        all_word_context_pairs.append([(word, context_word) for context_word in contexts])\n",
    "    return list(chain.from_iterable(all_word_context_pairs))\n",
    "\n",
    "def generate_word_contextword_pairs_dynamic(sentence, window_size=5): \n",
    "    # window size is dynamic. window_size parameter is the maximum allowed window_size.\n",
    "    # so for each word, win_size is uniformly sampled from [1, window_size]\n",
    "    # Ref: Goldberg and Levy 2014 \n",
    "\n",
    "    all_word_context_pairs = []\n",
    "    \n",
    "    for i, word in enumerate(sentence):\n",
    "        win_size = np.random.randint(low = 1, high = window_size+1 )\n",
    "#         win_size = window_size\n",
    "        contexts = sentence[i-win_size:i] + sentence[i+1:i+win_size+1]\n",
    "        all_word_context_pairs.append([(word, context_word) for context_word in contexts])\n",
    "    return list(chain.from_iterable(all_word_context_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "048bd9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_sh = list(chain.from_iterable([generate_word_contextword_pairs_dynamic(sentence,2) for sentence in corpus]))\n",
    "win_size=2\n",
    "data_sh = list(chain.from_iterable([generate_word_contextword_pairs(sentence,win_size) for sentence in corpus]))\n",
    "data = [(word_to_idx[a], word_to_idx[b]) for a,b in data_sh]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3da62991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [(torch.IntTensor([subword_to_idx[subword] for subword in char_ngrams_dict[a]])  , torch.IntTensor([word_to_idx[b]])) for a,b in data_sh[:10000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2ae97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_chars = []\n",
    "# data = []\n",
    "# i=0\n",
    "# for a,b in data_sh:\n",
    "#     data.append((i , torch.IntTensor([word_to_idx[b]])) )\n",
    "#     data_chars.append(torch.IntTensor([subword_to_idx[subword] for subword in char_ngrams_dict[a]]) )\n",
    "#     i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79d8ed05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60dd79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FastTextTorch(nn.Module):\n",
    "    \n",
    "#     def __init__(self,embedding_size, in_vocab_size,out_vocab_size, num_neg_samples,char_ngrams_dict, sampling_weights=None):\n",
    "#         super(FastTextTorch, self).__init__()\n",
    "#         self.input_embedding = nn.Embedding(in_vocab_size,embedding_size)\n",
    "#         self.output_embedding = nn.Embedding(out_vocab_size, embedding_size)\n",
    "        \n",
    "# #         r = 0.01/embedding_size\n",
    "# #         r = 5\n",
    "# #         torch.nn.init.uniform_(self.input_embedding.weight, -r, r)\n",
    "# #         torch.nn.init.uniform_(self.output_embedding.weight, -r, r)\n",
    "#         self.in_vocab_size = in_vocab_size\n",
    "#         self.out_vocab_size = out_vocab_size\n",
    "#         self.embedding_size = embedding_size      \n",
    "#         self.num_neg_samples = num_neg_samples\n",
    "#         self.char_ngrams_dict = char_ngrams_dict\n",
    "#         if sampling_weights is not None:\n",
    "#             self.sampling_weights = sampling_weights\n",
    "#         else:\n",
    "#             self.sampling_weights = torch.ones(self.out_vocab_size)/self.out_vocab_size\n",
    "            \n",
    "#     def get_input_embedding(self,inp):\n",
    "#         return torch.Tensor([model.input_embedding(data_chars[w].to(device)).sum(0) for w in inp])\n",
    "#     def forward(self, inputs, outputs):\n",
    "#         # Dont need forward. Computing loss dirictly is simpler\n",
    "# #         raise NotImplementedError\n",
    "        \n",
    "#         inp_em =  [self.input_embedding(data_chars[w].to(device)).sum(0) for w in inputs]\n",
    "#         out_em = self.output_embedding(outputs) \n",
    "#         out = torch.zeros((inputs.shape[0]))\n",
    "#         for i in torch.arange(inputs.shape[0]):\n",
    "#             out[i] = torch.sum(inp_em[i]*out_em[i])\n",
    "        \n",
    "        \n",
    "# #         for _ in out.shape[1:]:\n",
    "# #             out= out.sum(1)\n",
    "#         return out\n",
    "# #         return out.sum(1)\n",
    "    \n",
    "#     def negativeSampling(self, num_samples):        \n",
    "#         # returns indices of sampled words\n",
    "#         return torch.multinomial(self.sampling_weights, num_samples, replacement=True)\n",
    "    \n",
    "#     def loss(self, inputs, outputs, negative_samples):\n",
    "#         # Ref: Distributed Representations of Words and Phrasesand their Compositionality\n",
    "        \n",
    "# #         negative_samples = self.negativeSampling(self.num_neg_samples*inputs.shape[0]) # batch size = inputs.shape[0]\n",
    "# #         negative_samples = negative_samples.reshape(inputs.shape[0],self.num_neg_samples)\n",
    "# #         negative_samples = negative_samples.to(device)\n",
    "#         input_em = self.input_embedding(inputs)\n",
    "#         output_em = self.output_embedding(outputs)\n",
    "# #         print(input_em.shape)\n",
    "# #         print(output_em.shape)\n",
    "#         neg_samples_em = self.output_embedding(negative_samples)\n",
    "# #         print(neg_samples_em.shape/\n",
    "# #         print(input_em.repeat((self.num_neg_samples,1)).shape)\n",
    "#         loss_val_term1 = F.logsigmoid(torch.sum(input_em* output_em, dim=1))\n",
    "#         loss_val_term2 = torch.sum(F.logsigmoid(-torch.sum((input_em.unsqueeze(1).repeat((1,self.num_neg_samples,1))*neg_samples_em), dim=2)), dim=1)\n",
    "# #         print(\"loss_val_term1: \" + str(loss_val_term1.sum()) + \" || loss_val_term2: \" + str(loss_val_term2.sum()))\n",
    "# #         print(torch.mean(loss_val_term1 + loss_val_term2))\n",
    "# #         print(loss_val_term1.mean()+loss_val_term2.mean())\n",
    "#         return -torch.sum(loss_val_term1 + loss_val_term2)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7ab1c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FastTextTorch(nn.Module):\n",
    "    \n",
    "#     def __init__(self,embedding_size, in_vocab_size,out_vocab_size, num_neg_samples,char_ngrams_dict):\n",
    "#         super(FastTextTorch, self).__init__()\n",
    "#         self.input_embedding = nn.Linear(in_vocab_size,embedding_size)\n",
    "#         self.output_embedding = nn.Embedding(out_vocab_size, embedding_size)\n",
    "        \n",
    "# #         r = 0.01/embedding_size\n",
    "# #         r = 5\n",
    "# #         torch.nn.init.uniform_(self.input_embedding.weight, -r, r)\n",
    "# #         torch.nn.init.uniform_(self.output_embedding.weight, -r, r)\n",
    "#         self.in_vocab_size = in_vocab_size\n",
    "#         self.out_vocab_size = out_vocab_size\n",
    "#         self.embedding_size = embedding_size      \n",
    "#         self.num_neg_samples = num_neg_samples\n",
    "        \n",
    "#     def forward(self, inputs, outputs):        \n",
    "#         input_em = self.input_embedding(inputs)\n",
    "#         output_em = self.output_embedding(outputs)\n",
    "#         out = input_em*output_em\n",
    "#         return out.sum(1)\n",
    "    \n",
    "#     def negativeSampling(self, num_samples,sampling_weights):        \n",
    "#         # returns indices of sampled words\n",
    "#         return torch.multinomial(sampling_weights, num_samples, replacement=True)\n",
    "    \n",
    "#     def loss(self, inputs, outputs, negative_samples):\n",
    "#         # Ref: Distributed Representations of Words and Phrasesand their Compositionality\n",
    "        \n",
    "# #         negative_samples = self.negativeSampling(self.num_neg_samples*inputs.shape[0]) # batch size = inputs.shape[0]\n",
    "# #         negative_samples = negative_samples.reshape(inputs.shape[0],self.num_neg_samples)\n",
    "# #         negative_samples = negative_samples.to(device)\n",
    "#         input_em = self.input_embedding(inputs)\n",
    "#         output_em = self.output_embedding(outputs)\n",
    "# #         print(input_em.shape)\n",
    "# #         print(output_em.shape)\n",
    "#         neg_samples_em = self.output_embedding(negative_samples)\n",
    "# #         print(neg_samples_em.shape/\n",
    "# #         print(input_em.repeat((self.num_neg_samples,1)).shape)\n",
    "#         loss_val_term1 = F.logsigmoid(torch.sum(input_em* output_em, dim=1))\n",
    "#         loss_val_term2 = torch.sum(F.logsigmoid(-torch.sum((input_em.unsqueeze(1).repeat((1,self.num_neg_samples,1))*neg_samples_em), dim=2)), dim=1)\n",
    "# #         print(\"loss_val_term1: \" + str(loss_val_term1.sum()) + \" || loss_val_term2: \" + str(loss_val_term2.sum()))\n",
    "# #         print(torch.mean(loss_val_term1 + loss_val_term2))\n",
    "# #         print(loss_val_term1.mean()+loss_val_term2.mean())\n",
    "#         return -torch.sum(loss_val_term1 + loss_val_term2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b81b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FastTextTorch(nn.Module):\n",
    "    \n",
    "#     def __init__(self,embedding_size, in_vocab_size,out_vocab_size, num_neg_samples,char_ngrams_dict):\n",
    "#         super(FastTextTorch, self).__init__()\n",
    "#         self.input_embedding = nn.Embedding(in_vocab_size,embedding_size)\n",
    "#         self.output_embedding = nn.Embedding(out_vocab_size, embedding_size)\n",
    "        \n",
    "# #         r = 0.01/embedding_size\n",
    "# #         r = 5\n",
    "# #         torch.nn.init.uniform_(self.input_embedding.weight, -r, r)\n",
    "# #         torch.nn.init.uniform_(self.output_embedding.weight, -r, r)\n",
    "#         self.in_vocab_size = in_vocab_size\n",
    "#         self.out_vocab_size = out_vocab_size\n",
    "#         self.embedding_size = embedding_size      \n",
    "#         self.num_neg_samples = num_neg_samples\n",
    "        \n",
    "#     def forward(self, inputs, outputs): \n",
    "        \n",
    "#         inp_em = torch.zeros((outputs.shape[0], self.embedding_size), device=device)\n",
    "#         for i,w in enumerate(inputs):\n",
    "#             inp_em[i,:] = self.input_embedding(w).sum(0)\n",
    "\n",
    "#         output_em = self.output_embedding(outputs)\n",
    "#         return (inp_em*output_em).sum(1)\n",
    "    \n",
    "#     def negativeSampling(self, num_samples,sampling_weights):        \n",
    "#         # returns indices of sampled words\n",
    "#         return torch.multinomial(sampling_weights, num_samples, replacement=True)\n",
    "    \n",
    "#     def loss(self, inputs, outputs, negative_samples):\n",
    "#         # Ref: Distributed Representations of Words and Phrasesand their Compositionality\n",
    "        \n",
    "# #         negative_samples = self.negativeSampling(self.num_neg_samples*inputs.shape[0]) # batch size = inputs.shape[0]\n",
    "# #         negative_samples = negative_samples.reshape(inputs.shape[0],self.num_neg_samples)\n",
    "# #         negative_samples = negative_samples.to(device)\n",
    "#         input_em = self.input_embedding(inputs)\n",
    "#         output_em = self.output_embedding(outputs)\n",
    "# #         print(input_em.shape)\n",
    "# #         print(output_em.shape)\n",
    "#         neg_samples_em = self.output_embedding(negative_samples)\n",
    "# #         print(neg_samples_em.shape/\n",
    "# #         print(input_em.repeat((self.num_neg_samples,1)).shape)\n",
    "#         loss_val_term1 = F.logsigmoid(torch.sum(input_em* output_em, dim=1))\n",
    "#         loss_val_term2 = torch.sum(F.logsigmoid(-torch.sum((input_em.unsqueeze(1).repeat((1,self.num_neg_samples,1))*neg_samples_em), dim=2)), dim=1)\n",
    "# #         print(\"loss_val_term1: \" + str(loss_val_term1.sum()) + \" || loss_val_term2: \" + str(loss_val_term2.sum()))\n",
    "# #         print(torch.mean(loss_val_term1 + loss_val_term2))\n",
    "# #         print(loss_val_term1.mean()+loss_val_term2.mean())\n",
    "#         return -torch.sum(loss_val_term1 + loss_val_term2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb18964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0852e3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61702b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed165bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inp_and_offsets(inputs):\n",
    "    aa = []\n",
    "    offsets = [0]\n",
    "    for lst in inputs:\n",
    "#         tmp = word_indx_to_char[lst].numpy()\n",
    "        tmp = word_indx_to_char[lst]\n",
    "        aa.append(tmp)\n",
    "        offsets.append(len(tmp)+offsets[-1])\n",
    "    offsets.pop(-1)\n",
    "    return torch.tensor(list(chain.from_iterable(aa))).to(device), torch.tensor(offsets).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "861c5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTextTorch(nn.Module):\n",
    "    \n",
    "    def __init__(self,embedding_size, in_vocab_size,out_vocab_size, num_neg_samples,char_ngrams_dict):\n",
    "        super(FastTextTorch, self).__init__()\n",
    "        self.input_embedding = nn.EmbeddingBag(in_vocab_size,embedding_size)\n",
    "        self.output_embedding = nn.Embedding(out_vocab_size, embedding_size)\n",
    "        \n",
    "#         r = 0.01/embedding_size\n",
    "#         r = 5\n",
    "#         torch.nn.init.uniform_(self.input_embedding.weight, -r, r)\n",
    "#         torch.nn.init.uniform_(self.output_embedding.weight, -r, r)\n",
    "        self.in_vocab_size = in_vocab_size\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_size = embedding_size      \n",
    "        self.num_neg_samples = num_neg_samples\n",
    "        \n",
    "    def forward(self, inputs, outputs):        \n",
    "        inp, offsets = get_inp_and_offsets(inputs)\n",
    "        input_em = self.input_embedding(inp, offsets)\n",
    "        output_em = self.output_embedding(outputs)\n",
    "        out = input_em*output_em\n",
    "        return out.sum(1)\n",
    "    \n",
    "    def negativeSampling(self, num_samples,sampling_weights):        \n",
    "        # returns indices of sampled words\n",
    "        return torch.multinomial(sampling_weights, num_samples, replacement=True)\n",
    "    \n",
    "    def loss(self, inputs, outputs, negative_samples):\n",
    "        # Ref: Distributed Representations of Words and Phrasesand their Compositionality\n",
    "        \n",
    "#         negative_samples = self.negativeSampling(self.num_neg_samples*inputs.shape[0]) # batch size = inputs.shape[0]\n",
    "#         negative_samples = negative_samples.reshape(inputs.shape[0],self.num_neg_samples)\n",
    "#         negative_samples = negative_samples.to(device)\n",
    "        input_em = self.input_embedding(inputs)\n",
    "        output_em = self.output_embedding(outputs)\n",
    "#         print(input_em.shape)\n",
    "#         print(output_em.shape)\n",
    "        neg_samples_em = self.output_embedding(negative_samples)\n",
    "#         print(neg_samples_em.shape/\n",
    "#         print(input_em.repeat((self.num_neg_samples,1)).shape)\n",
    "        loss_val_term1 = F.logsigmoid(torch.sum(input_em* output_em, dim=1))\n",
    "        loss_val_term2 = torch.sum(F.logsigmoid(-torch.sum((input_em.unsqueeze(1).repeat((1,self.num_neg_samples,1))*neg_samples_em), dim=2)), dim=1)\n",
    "#         print(\"loss_val_term1: \" + str(loss_val_term1.sum()) + \" || loss_val_term2: \" + str(loss_val_term2.sum()))\n",
    "#         print(torch.mean(loss_val_term1 + loss_val_term2))\n",
    "#         print(loss_val_term1.mean()+loss_val_term2.mean())\n",
    "        return -torch.sum(loss_val_term1 + loss_val_term2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d1dd3879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FastTextTorch(nn.Module):\n",
    "    \n",
    "#     def __init__(self,embedding_size, in_vocab_size,out_vocab_size, num_neg_samples,char_ngrams_dict, sampling_weights):\n",
    "#         super(FastTextTorch, self).__init__()\n",
    "#         self.input_embedding = nn.Linear(in_vocab_size,embedding_size, bias=False)\n",
    "#         self.output_embedding = nn.Embedding(out_vocab_size, embedding_size)\n",
    "        \n",
    "# #         r = 0.01/embedding_size\n",
    "# #         r = 5\n",
    "# #         torch.nn.init.uniform_(self.input_embedding.weight, -r, r)\n",
    "# #         torch.nn.init.uniform_(self.output_embedding.weight, -r, r)\n",
    "#         self.in_vocab_size = in_vocab_size\n",
    "#         self.out_vocab_size = out_vocab_size\n",
    "#         self.embedding_size = embedding_size      \n",
    "#         self.num_neg_samples = num_neg_samples\n",
    "#         self.sampling_weights = sampling_weights\n",
    "        \n",
    "#     def forward(self, inputs, outputs): \n",
    "        \n",
    "#         inp_em = self.input_embedding(inputs)\n",
    "#         output_em = self.output_embedding(outputs)\n",
    "#         return (inp_em*output_em).sum(1)\n",
    "    \n",
    "#     def negativeSampling(self, num_samples,sampling_weights):        \n",
    "#         # returns indices of sampled words\n",
    "# #         out = torch.zeros(num_samples, device=device, dtype=torch.int64)\n",
    "# #         torch.multinomial(self.sampling_weights, num_samples, replacement=True, out=out)\n",
    "# #         return out\n",
    "#         return torch.multinomial(self.sampling_weights, num_samples, replacement=True)\n",
    "    \n",
    "#     def loss(self, inputs, outputs, negative_samples):\n",
    "#         # Ref: Distributed Representations of Words and Phrasesand their Compositionality\n",
    "        \n",
    "# #         negative_samples = self.negativeSampling(self.num_neg_samples*inputs.shape[0]) # batch size = inputs.shape[0]\n",
    "# #         negative_samples = negative_samples.reshape(inputs.shape[0],self.num_neg_samples)\n",
    "# #         negative_samples = negative_samples.to(device)\n",
    "#         input_em = self.input_embedding(inputs)\n",
    "#         output_em = self.output_embedding(outputs)\n",
    "# #         print(input_em.shape)\n",
    "# #         print(output_em.shape)\n",
    "#         neg_samples_em = self.output_embedding(negative_samples)\n",
    "# #         print(neg_samples_em.shape/\n",
    "# #         print(input_em.repeat((self.num_neg_samples,1)).shape)\n",
    "#         loss_val_term1 = F.logsigmoid(torch.sum(input_em* output_em, dim=1))\n",
    "#         loss_val_term2 = torch.sum(F.logsigmoid(-torch.sum((input_em.unsqueeze(1).repeat((1,self.num_neg_samples,1))*neg_samples_em), dim=2)), dim=1)\n",
    "# #         print(\"loss_val_term1: \" + str(loss_val_term1.sum()) + \" || loss_val_term2: \" + str(loss_val_term2.sum()))\n",
    "# #         print(torch.mean(loss_val_term1 + loss_val_term2))\n",
    "# #         print(loss_val_term1.mean()+loss_val_term2.mean())\n",
    "#         return -torch.sum(loss_val_term1 + loss_val_term2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "89011074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.index_select(model.input_embedding.weight,0, torch.IntTensor(word_indx_to_char[word_indx[0]]).to(device)).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e272ddbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6610.19"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9b182851",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastTextTorch(embedding_size=100, in_vocab_size=vocab_size,out_vocab_size=vocab_w_size, char_ngrams_dict=char_ngrams_dict, num_neg_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "9047d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ed622c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "76e598a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CorpusDataset(torch.utils.data.Dataset):\n",
    "#     \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "#     def __init__(self, data, transform=None):\n",
    "        \n",
    "#         self.data = data\n",
    "# #         self.transform = transform\n",
    "        \n",
    "#     def transform(self,x):\n",
    "#         r = torch.zeros(model.in_vocab_size)\n",
    "#         r[word_indx_to_char[x]] = 1\n",
    "#         return r\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if torch.is_tensor(idx):\n",
    "#             idx = idx.tolist()\n",
    "\n",
    "#         sample = data[idx]\n",
    "\n",
    "#         if self.transform:\n",
    "#             sample = (self.transform(sample[0]), torch.tensor(sample[1]))\n",
    "\n",
    "#         return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f89b4b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# data = data[:10000]\n",
    "# device ='cpu'\n",
    "nb=500\n",
    "lr =0.01\n",
    "n_epochs = 300\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# training\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "loss_values =[]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "# optimizer = torch.optim.LBFGS(model_N.parameters())\n",
    "dataloader = torch.utils.data.DataLoader(data, batch_size=int(len(data)/nb), shuffle=True) # \n",
    "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda= lambda epoch_i_dl: (1-epoch_i_dl/(len(dataloader)*n_epochs)))\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[ 100, 150, 200], gamma=0.1)\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "#                                                 max_lr=0.025, \n",
    "#                                                 steps_per_epoch=len(dataloader), \n",
    "# #                                                 anneal_strategy = 'linear',\n",
    "#                                                 epochs=n_epochs\n",
    "#                                                )\n",
    "loss_func = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "# dataloader = torch.utils.data.DataLoader(CorpusDataset(data[:10000]), batch_size=64, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "32aa0ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "3cf08f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6610190"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5c398aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8916"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "29032732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8916"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_indx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "61cce78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputVector(inp_word_indx):\n",
    "    # inp: batch_size x 1\n",
    "    inp_vec = torch.zeros(inp_word_indx.shape[0], len(subword_to_idx))\n",
    "    \n",
    "    for i,word_i in enumerate(inp_word_indx):\n",
    "        inp_vec[i,word_indx_to_char[word_i].long()] = 1\n",
    "    \n",
    "#     for i,word_i in enumerate(inp):\n",
    "#         for subword in char_ngrams_dict[indx_to_word[word_i.item()]]:\n",
    "#             inp_vec[i,subword_to_idx[subword]] = 1\n",
    "    return inp_vec\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ed676d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getInputVector(inp):\n",
    "#     # inp: batch_size x 1\n",
    "#     inp_vec = torch.zeros(inp.shape[0], len(subword_to_idx))\n",
    "#     for i,word_i in enumerate(inp):\n",
    "#         for subword in char_ngrams_dict[indx_to_word[word_i.item()]]:\n",
    "#             inp_vec[i,subword_to_idx[subword]] = 1\n",
    "#     return inp_vec\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c7ebb930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inp_and_offsets_transform(inputs):\n",
    "    aa = []\n",
    "    offsets = [0]\n",
    "    for lst in inputs:\n",
    "#         tmp = word_indx_to_char[lst].numpy()\n",
    "        tmp = word_indx_to_char[lst]\n",
    "        aa.append(tmp)\n",
    "        offsets.append(len(tmp)+offsets[-1])\n",
    "    offsets.pop(-1)\n",
    "    return (torch.tensor(list(chain.from_iterable(aa))), torch.tensor(offsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "662d221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sh = list(chain.from_iterable([generate_word_contextword_pairs_dynamic(sentence,win_size) for sentence in corpus]))\n",
    "data = [(word_to_idx[a], word_to_idx[b]) for a,b in data_sh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "17570721",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(data, batch_size=int(len(data)/nb), shuffle=True) #int(len(data)/nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "7ec450cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = torch.utils.data.DataLoader(CorpusDataset(data[:100000]), batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "650cff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_indx, context_word_indx = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8ce30320",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# dataloader = torch.utils.data.DataLoader(CorpusDataset(data[:100000]), batch_size=1024, shuffle=True,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "99b68c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "04ec199c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([10,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c26c1cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr0=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "1707be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values =[]\n",
    "def train(model, n_epochs):\n",
    "    start = time.time()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr0)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda= lambda epoch_i_dl: max([0.0001, 1-epoch_i_dl/(nb*n_epochs)]))\n",
    "    for epoch in trange(n_epochs):\n",
    "        loss_total = 0\n",
    "\n",
    "        data_sh = list(chain.from_iterable([generate_word_contextword_pairs_dynamic(sentence,win_size) for sentence in corpus]))\n",
    "        data = [(word_to_idx[a], word_to_idx[b]) for a,b in data_sh]\n",
    "        dataloader = torch.utils.data.DataLoader(data, batch_size=int(len(data)/nb), shuffle=True) \n",
    "#         dataloader = torch.utils.data.DataLoader(data[:100000], batch_size=int(len(data)/nb), shuffle=True) #int(len(data)/nb)\n",
    "                # zero the gradients\n",
    "    #     optimizer.zero_grad()     \n",
    "        \n",
    "       \n",
    "        i_dl=0\n",
    "        for word_indx, context_word_indx in dataloader:\n",
    "\n",
    "    #         # zero the gradients\n",
    "    #         loss.zero_grad()\n",
    "            optimizer.zero_grad()    \n",
    "\n",
    "            # compute loss\n",
    "            \n",
    "#             inp = word_indx.to(device)\n",
    "            outp = context_word_indx.to(device)\n",
    "            \n",
    "    #             inp = [word_indx_to_char[w].to(device) for w in word_indx]\n",
    "#             inp = word_indx.numpy()\n",
    "            inp = word_indx.tolist()\n",
    "#             inp = word_indx.to(device)\n",
    "    #             inp = getInputVector(word_indx)\n",
    "    #             inp =inp.to(device)\n",
    "#             outp = context_word_indx.to(device)\n",
    "    #         inp = torch.IntTensor([word_indx])\n",
    "    #         outp = torch.IntTensor([context_word_indx])\n",
    "         # pred \n",
    "    #         negative_samples = model.negativeSampling(model.num_neg_samples*inp.shape[0]) # batch size = inputs.shape[0]\n",
    "    #         negative_samples = negative_samples.reshape(inp.shape[0],model.num_neg_samples)\n",
    "    #         negative_samples = negative_samples.to(device)\n",
    "\n",
    "    #         loss = model.loss(inp, outp,negative_samples)\n",
    "            pred_p = model(inp,outp)\n",
    "    # #         pred_n = model(inp.unsqueeze(1).repeat((1,model.num_neg_samples)),negative_samples)\n",
    "            loss = loss_func(pred_p, pred_p*0+1)\n",
    "            for _ in range(model.num_neg_samples):\n",
    "                negative_samples = model.negativeSampling(outp.shape[0], sampling_dist) # batch size = inputs.shape[0]\n",
    "                negative_samples = negative_samples.to(device)\n",
    "                pred_n = model(inp,negative_samples)\n",
    "\n",
    "\n",
    "            loss += loss_func(pred_n, pred_n*0)\n",
    "            \n",
    "            loss_total += loss.item()\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "\n",
    "\n",
    "            # optimization step\n",
    "            optimizer.step()\n",
    "    #         model.input_embedding.weight.data -= model.input_embedding.weight.grad*lr\n",
    "    #         model.output_embedding.weight.data -= model.output_embedding.weight.grad*lr\n",
    "    #         model.input_embedding.weight.grad.zero_()\n",
    "    #         model.output_embedding.weight.grad.zero_()\n",
    "\n",
    "            scheduler.step()\n",
    "            \n",
    "#             epoch_i_dl = (epoch+1)*(i_dl+1)\n",
    "#             i_dl += 1\n",
    "#             print(scheduler.get_last_lr())\n",
    "#             print(\"i_dl: \"+ str(i_dl))\n",
    "#             print(\"epoch_i_dl: \" + str(epoch_i_dl))\n",
    "#             print((1-epoch_i_dl/(nb*n_epochs)))\n",
    "        loss_values.append(loss_total)\n",
    "    #     if epoch > 10:\n",
    "    #         if (loss_values[-1] - loss_values[-2]) < 0.5*(loss_values[-2] - loss_values[-3]):\n",
    "    #             lr = min([lr/2,0.0000025])\n",
    "        \n",
    "        if epoch%10 ==0:\n",
    "            print(\"Epoch \" + str(epoch) + \" done. Loss: \" + str(loss_total))\n",
    "            print(\"Next step size: \" + str(scheduler.get_last_lr()[0]))\n",
    "            torch.save(model, 'saved_model_ft.pkl')\n",
    "    # print(loss_values)\n",
    "    # print(\"Epoch \" + str(epoch) + \" done. Loss: \" + str(loss_total))\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"Model trained for {n_epochs} in {elapsed/60: .2f} minutes\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "5523ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit word_indx_to_char[wi[1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "6c42060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'saved_model_ft_100epochs_dynamic_linearLRdecay.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "672236d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdccb31f3874f59adcbb07312b4fef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 done. Loss: 8288001.087814331\n",
      "Next step size: 0.0098998\n",
      "Epoch 10 done. Loss: 4516544.004104614\n",
      "Next step size: 0.0088978\n",
      "Epoch 20 done. Loss: 4357115.191864014\n",
      "Next step size: 0.0078958\n",
      "Epoch 30 done. Loss: 4280237.81690979\n",
      "Next step size: 0.006894\n",
      "Epoch 40 done. Loss: 4222921.356201172\n",
      "Next step size: 0.005892\n",
      "Epoch 50 done. Loss: 4174373.1633911133\n",
      "Next step size: 0.00489\n",
      "Epoch 60 done. Loss: 4128625.9540863037\n",
      "Next step size: 0.0038880000000000004\n",
      "Epoch 70 done. Loss: 4086992.235687256\n",
      "Next step size: 0.0028859999999999997\n",
      "Epoch 80 done. Loss: 4046863.1100769043\n",
      "Next step size: 0.0018840000000000003\n",
      "Epoch 90 done. Loss: 4005807.1872558594\n",
      "Next step size: 0.0008819999999999994\n",
      "\n",
      "Model trained for 100 in  323.95 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 19432.5 s\n",
       "File: <ipython-input-244-c7fb9cc6475f>\n",
       "Function: train at line 2\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     2                                           def train(model, n_epochs):\n",
       "     3         1          3.0      3.0      0.0      start = time.time()\n",
       "     4         1     360706.0 360706.0      0.0      gc.collect()\n",
       "     5         1         15.0     15.0      0.0      torch.cuda.empty_cache()\n",
       "     6         1        121.0    121.0      0.0      optimizer = torch.optim.Adam(model.parameters(), lr = lr0)\n",
       "     7         1        117.0    117.0      0.0      scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda= lambda epoch_i_dl: max([0.0001, 1-epoch_i_dl/(nb*n_epochs)]))\n",
       "     8       101     328869.0   3256.1      0.0      for epoch in trange(n_epochs):\n",
       "     9       100        282.0      2.8      0.0          loss_total = 0\n",
       "    10                                           \n",
       "    11       100 1990276378.0 19902763.8     10.2          data_sh = list(chain.from_iterable([generate_word_contextword_pairs_dynamic(sentence,win_size) for sentence in corpus]))\n",
       "    12       100  306708332.0 3067083.3      1.6          data = [(word_to_idx[a], word_to_idx[b]) for a,b in data_sh]\n",
       "    13       100   24617997.0 246180.0      0.1          dataloader = torch.utils.data.DataLoader(data, batch_size=int(len(data)/nb), shuffle=True) \n",
       "    14                                           #         dataloader = torch.utils.data.DataLoader(data[:100000], batch_size=int(len(data)/nb), shuffle=True) #int(len(data)/nb)\n",
       "    15                                                           # zero the gradients\n",
       "    16                                               #     optimizer.zero_grad()     \n",
       "    17                                                   \n",
       "    18                                                  \n",
       "    19       100        439.0      4.4      0.0          i_dl=0\n",
       "    20     50199 4638651082.0  92405.2     23.9          for word_indx, context_word_indx in dataloader:\n",
       "    21                                           \n",
       "    22                                               #         # zero the gradients\n",
       "    23                                               #         loss.zero_grad()\n",
       "    24     50099    7579697.0    151.3      0.0              optimizer.zero_grad()    \n",
       "    25                                           \n",
       "    26                                                       # compute loss\n",
       "    27                                                       \n",
       "    28                                           #             inp = word_indx.to(device)\n",
       "    29     50099  133051394.0   2655.8      0.7              outp = context_word_indx.to(device)\n",
       "    30                                                       \n",
       "    31                                               #             inp = [word_indx_to_char[w].to(device) for w in word_indx]\n",
       "    32                                           #             inp = word_indx.numpy()\n",
       "    33     50099   19780159.0    394.8      0.1              inp = word_indx.tolist()\n",
       "    34                                           #             inp = word_indx.to(device)\n",
       "    35                                               #             inp = getInputVector(word_indx)\n",
       "    36                                               #             inp =inp.to(device)\n",
       "    37                                           #             outp = context_word_indx.to(device)\n",
       "    38                                               #         inp = torch.IntTensor([word_indx])\n",
       "    39                                               #         outp = torch.IntTensor([context_word_indx])\n",
       "    40                                                    # pred \n",
       "    41                                               #         negative_samples = model.negativeSampling(model.num_neg_samples*inp.shape[0]) # batch size = inputs.shape[0]\n",
       "    42                                               #         negative_samples = negative_samples.reshape(inp.shape[0],model.num_neg_samples)\n",
       "    43                                               #         negative_samples = negative_samples.to(device)\n",
       "    44                                           \n",
       "    45                                               #         loss = model.loss(inp, outp,negative_samples)\n",
       "    46     50099 1680025224.0  33534.1      8.6              pred_p = model(inp,outp)\n",
       "    47                                               # #         pred_n = model(inp.unsqueeze(1).repeat((1,model.num_neg_samples)),negative_samples)\n",
       "    48     50099   11917385.0    237.9      0.1              loss = loss_func(pred_p, pred_p*0+1)\n",
       "    49    300594    1251747.0      4.2      0.0              for _ in range(model.num_neg_samples):\n",
       "    50    250495  439029242.0   1752.6      2.3                  negative_samples = model.negativeSampling(outp.shape[0], sampling_dist) # batch size = inputs.shape[0]\n",
       "    51    250495  608214038.0   2428.0      3.1                  negative_samples = negative_samples.to(device)\n",
       "    52    250495 8481169579.0  33857.6     43.6                  pred_n = model(inp,negative_samples)\n",
       "    53                                           \n",
       "    54                                           \n",
       "    55     50099   11060887.0    220.8      0.1              loss += loss_func(pred_n, pred_n*0)\n",
       "    56                                                       \n",
       "    57     50099  195633451.0   3904.9      1.0              loss_total += loss.item()\n",
       "    58                                                       # backward pass\n",
       "    59     50099  855965777.0  17085.5      4.4              loss.backward()\n",
       "    60                                           \n",
       "    61                                           \n",
       "    62                                                       # optimization step\n",
       "    63     50099   20032550.0    399.9      0.1              optimizer.step()\n",
       "    64                                               #         model.input_embedding.weight.data -= model.input_embedding.weight.grad*lr\n",
       "    65                                               #         model.output_embedding.weight.data -= model.output_embedding.weight.grad*lr\n",
       "    66                                               #         model.input_embedding.weight.grad.zero_()\n",
       "    67                                               #         model.output_embedding.weight.grad.zero_()\n",
       "    68                                           \n",
       "    69     50099    3267737.0     65.2      0.0              scheduler.step()\n",
       "    70                                                       \n",
       "    71                                           #             epoch_i_dl = (epoch+1)*(i_dl+1)\n",
       "    72                                           #             i_dl += 1\n",
       "    73                                           #             print(scheduler.get_last_lr())\n",
       "    74                                           #             print(\"i_dl: \"+ str(i_dl))\n",
       "    75                                           #             print(\"epoch_i_dl: \" + str(epoch_i_dl))\n",
       "    76                                           #             print((1-epoch_i_dl/(nb*n_epochs)))\n",
       "    77       100        305.0      3.0      0.0          loss_values.append(loss_total)\n",
       "    78                                               #     if epoch > 10:\n",
       "    79                                               #         if (loss_values[-1] - loss_values[-2]) < 0.5*(loss_values[-2] - loss_values[-3]):\n",
       "    80                                               #             lr = min([lr/2,0.0000025])\n",
       "    81                                                   \n",
       "    82       100        223.0      2.2      0.0          if epoch%10 ==0:\n",
       "    83        10       1029.0    102.9      0.0              print(\"Epoch \" + str(epoch) + \" done. Loss: \" + str(loss_total))\n",
       "    84        10        406.0     40.6      0.0              print(\"Next step size: \" + str(scheduler.get_last_lr()[0]))\n",
       "    85        10    3570748.0 357074.8      0.0              torch.save(model, 'saved_model_ft.pkl')\n",
       "    86                                               # print(loss_values)\n",
       "    87                                               # print(\"Epoch \" + str(epoch) + \" done. Loss: \" + str(loss_total))\n",
       "    88         1          4.0      4.0      0.0      elapsed = time.time() - start\n",
       "    89         1         41.0     41.0      0.0      print(f\"Model trained for {n_epochs} in {elapsed/60: .2f} minutes\")\n",
       "    90         1          1.0      1.0      0.0      return model"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "model.to(device)\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "%lprun -f train  model = train(model, n_epochs=100)\n",
    "# model = train(model, n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae83a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c1144ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.index_select(model.input_embedding.weight,0, torch.IntTensor(word_indx_to_char[word_indx[0]]).to(device)).sum(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b4facf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8faaad3040>]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc0b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indx_to_char[word_indx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8e146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b57694fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "model.to('cpu')\n",
    "# em = nn.Linear(model.in_vocab_size, model.embedding_size)\n",
    "\n",
    "# em.weight = model.input_embedding.weight\n",
    "# em.weight.requires_grad = False\n",
    "# word_emb = em.weight.numpy()\n",
    "\n",
    "em = nn.EmbeddingBag.from_pretrained(model.input_embedding.weight, freeze=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b73ca331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp, offsets = get_inp_and_offsets(torch.IntTensor([100]))\n",
    "\n",
    "# cosineSimilarity(word_vec, em(inp, offsets).numpy().squeeze())\n",
    "\n",
    "# word_to_idx['జిల్లా']\n",
    "\n",
    "# em(inp, offsets).numpy().squeeze()\n",
    "\n",
    "# word_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e9f8fd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('వరి', 0.5933918952941895),\n",
       " ('కూరగాయలు', 0.5736520886421204),\n",
       " ('పంటలను', 0.5348685383796692),\n",
       " ('పండు', 0.5330380797386169),\n",
       " ('విత్తనాలు', 0.5318567752838135),\n",
       " ('పత్తి', 0.5299122333526611),\n",
       " ('ప్రత్తి', 0.5249885320663452),\n",
       " ('చెరకు', 0.5114282369613647),\n",
       " ('పప్పు', 0.5006212592124939),\n",
       " ('వర్షాలు', 0.49976930022239685)]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# findSimilar('queen', word_emb,10)\n",
    "# word = 'తక్కువ' #'లోపల'#'పాలు'#'సమీప'#'దివ్యాంగుల'#'జైపూర్'\n",
    "word = 'పంటలు'#'నీరు'#'తక్కువ' #'పాలు'#'అన్న' #'అక్కడ' #'దేశం'\n",
    "# word = 'దక్షిణ'#'తండ్రి'\n",
    "# word = 'నక్షత్రం'#'బంగారు'#'విద్య'#'రాజ్యాంగం'#'ఇథియోపియా'#'బిలియన్ల'#'నదులు'#'యుద్ధం'#'మొక్కలు'#'గాంధీ'#'విజయం'#'అభివృద్ధి'\n",
    "# word = 'ఎనిమిది'#'కుటుంబం'#'ఆలయ'#'సాయంత్రం'#'నక్షత్రం' #'దిగుమతి'#'పాఠశాల'#'వినియోగం'\n",
    "# word = 'గ్రామం'\n",
    "# word = 'ప్రముఖ'#'లక్ష'#'ప్రముఖ'#'జర్మన్'#'ప్రజలు'#'గుండె'#'మట్టి'#'ఆధిక్యత'#'చెట్లు'#'పెద్ద'#'ఆధారిత'#'ఇతర'#'జిల్లా'#'ఒకటి'#'దూరం' #'కణాలు'\n",
    "# model.input_embedding.requires_grad_(False)\n",
    "findSimilar_N(word, em, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c9d0fab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('మంటలు', 0.6825847029685974),\n",
       " ('పాఠశాలకు', 0.6818782687187195),\n",
       " ('గంటలు', 0.6803637742996216),\n",
       " ('పంట', 0.6578326225280762),\n",
       " ('చెరుకు', 0.6567128300666809),\n",
       " ('పాటలు', 0.6536258459091187),\n",
       " ('వ్యాసాలు', 0.6505818367004395),\n",
       " ('పరిశ్రమల', 0.6488710045814514),\n",
       " ('రకరకాల', 0.6432406902313232),\n",
       " ('విశ్రాంతి', 0.6415542364120483)]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# findSimilar('queen', word_emb,10)\n",
    "# word = 'పది'\n",
    "# word ='అన్న'\n",
    "word = 'పంటలు'#'నీరు'#'తక్కువ' #'పాలు'#'అన్న' #'అక్కడ' #'దేశం'\n",
    "# model.input_embedding.requires_grad_(False)\n",
    "findSimilar_N(word, em, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77a1138",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, offsets = get_inp_and_offsets(torch.IntTensor([word_to_idx[word]]))\n",
    "word_vec = em(inp, offsets)\n",
    "word_vec = word_vec.detach().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "56bcf132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSimilar_N(word, em, k=5):\n",
    "    inp, offsets = get_inp_and_offsets(torch.IntTensor([word_to_idx[word]]))\n",
    "    word_vec = em(inp, offsets)\n",
    "    word_vec = word_vec.detach().numpy().squeeze()\n",
    "\n",
    "    sim = np.zeros(len(indx_to_word.keys()))\n",
    "    for i,row in enumerate(indx_to_word.keys()):\n",
    "        inp, offsets = get_inp_and_offsets(torch.IntTensor([row]))\n",
    "        row_v = em(inp, offsets).detach().numpy().squeeze()\n",
    "        sim[i] = cosineSimilarity(word_vec, row_v)\n",
    "\n",
    "    val,ind = torch.topk(torch.Tensor(sim), k+1)\n",
    "#     plt.scatter(np.arange(len(sim)),sim)\n",
    "#     print(val)\n",
    "#     print(ind)\n",
    "#     print(row.shape)\n",
    "    return [(indx_to_word[ind[i].item()], val[i].item() )for i in np.arange(1, len(ind))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccdd150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSimilar(word, em, k=5):\n",
    "    word_vec = em(getInputVector(torch.IntTensor([word_to_idx[word]])))\n",
    "    word_vec = word_vec.detach().numpy().squeeze()\n",
    "\n",
    "    sim = np.zeros(len(indx_to_word.keys()))\n",
    "    for i,row in enumerate(indx_to_word.keys()):\n",
    "        row_v = em(getInputVector(torch.IntTensor([row]))).detach().numpy().squeeze()\n",
    "        sim[i] = cosineSimilarity(word_vec, row_v)\n",
    "\n",
    "    val,ind = torch.topk(torch.Tensor(sim), k+1)\n",
    "#     plt.scatter(np.arange(len(sim)),sim)\n",
    "#     print(val)\n",
    "#     print(ind)\n",
    "#     print(row.shape)\n",
    "    return [(indx_to_word[ind[i].item()], val[i].item() )for i in np.arange(1, len(ind))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b5162edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineSimilarity(w1, w2):\n",
    "    return np.dot(w1,w2)/(np.linalg.norm(w1) * np.linalg.norm(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4eecbb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indx, context_word_indx = next(iter(dataloader))\n",
    "# context_word_indx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "91a656f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1876, 1751, 1678,  ..., 2829, 1511, 1808])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_indx.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "37ef2ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 77341])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_embedding.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1534fe4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 µs ± 5.26 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model.input_embedding.weight[:,word_indx[0].bool()].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "159893bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f42bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_indx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee4a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indx_to_char[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae8aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_em =  [model.input_embedding(word_indx_to_char[w].to(device)).sum(0) for w in inp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_em[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outp = context_word_indx.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
