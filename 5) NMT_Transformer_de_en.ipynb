{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee191433",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1631108771414,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "856bf53f"
   },
   "outputs": [],
   "source": [
    "# %config Completer.use_jedi=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0630b5e",
   "metadata": {
    "executionInfo": {
     "elapsed": 1698,
     "status": "ok",
     "timestamp": 1631108773103,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "5166304d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ff6828a",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1631108773103,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "5ef5db9f"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from tqdm.auto import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9670f971",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1631108773104,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "b1d42b73"
   },
   "outputs": [],
   "source": [
    "pd.options.display.width = 1200\n",
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14a1bab1",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1631108773105,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "006122bc"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from collections import Counter,OrderedDict\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa889908",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1631108773105,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "85a55754"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71a10650",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1631108774433,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "db414605",
    "outputId": "3e0ed1f8-1caa-436e-d10d-05afd8d73892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device.type.upper()} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56097353",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1631108774434,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "rrsZe5cvy_S-"
   },
   "outputs": [],
   "source": [
    "# random seeds\n",
    "SEED = 22\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9bfa7c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 957
    },
    "executionInfo": {
     "elapsed": 9098,
     "status": "ok",
     "timestamp": 1631108783519,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "2LIz7FRKOFIr",
    "outputId": "3ba6aafb-b8a5-4333-e9e0-6a88bb9268f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.12.1-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 5.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
      "\u001b[K     |████████████████████████████████| 170 kB 50.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
      "Collecting configparser>=3.8.1\n",
      "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Collecting subprocess32>=3.5.3\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 4.4 MB/s \n",
      "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.3.1-py2.py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 53.3 MB/s \n",
      "\u001b[?25hCollecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 1.3 MB/s \n",
      "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
      "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
      "Building wheels for collected packages: subprocess32, pathtools\n",
      "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=05f9d98888fc28025518fa6166a2257a2ed0b032ce92a6fe9a55e56911d4d472\n",
      "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=8ba627d3bfa14e6aa56563f0850ac871b020bfe11811866299558437e7f0df0d\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
      "Successfully built subprocess32 pathtools\n",
      "Installing collected packages: smmap, gitdb, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
      "Successfully installed GitPython-3.1.18 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.3.1 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.12.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "configparser"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2662722",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "executionInfo": {
     "elapsed": 26202,
     "status": "ok",
     "timestamp": 1631108809716,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "c0bVXv_Nz3_C",
    "outputId": "328b8507-dd95-43f9-df13-c168a4b60ad4"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Paste an API key from your profile and hit enter: ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25a6bf17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1631108813849,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "174b6f22",
    "outputId": "f90e40ac-7623-48d4-fac1-66d6d6cfd41e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650b8368",
   "metadata": {
    "id": "xOMick_Zytsg"
   },
   "source": [
    "# Mount drive for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1bde5fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20022,
     "status": "ok",
     "timestamp": 1631108841640,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "EM0oOFbJywSX",
    "outputId": "f4e3275e-a3b7-4aa1-de66-81419081ec4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f93ca46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1631108846670,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "tv9pAdOlyyZw",
    "outputId": "dde8f226-10b3-4309-95a1-6916e7e540b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/PyTorch\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive/PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75619732",
   "metadata": {
    "id": "885172ba"
   },
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2871be8e",
   "metadata": {
    "executionInfo": {
     "elapsed": 3097,
     "status": "ok",
     "timestamp": 1631108856452,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "4a8d4a56"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = torchtext.datasets.Multi30k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c431a7af",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1631108856453,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "7fefb08e"
   },
   "outputs": [],
   "source": [
    "dataset_train = torchtext.data.to_map_style_dataset(train_data)\n",
    "dataset_test = torchtext.data.to_map_style_dataset(test_data)\n",
    "dataset_valid = torchtext.data.to_map_style_dataset(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "297909f7",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1631108856453,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "da25fc09"
   },
   "outputs": [],
   "source": [
    "SRC = 'German'\n",
    "TRG = 'English'\n",
    "FILE_SUFFIX = 'en-de'\n",
    "SRC_LANG = 'de'\n",
    "TRG_LANG = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca72e0d7",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1631108856454,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "255c9955"
   },
   "outputs": [],
   "source": [
    "# SRC = 'Telugu'\n",
    "# TRG = 'English'\n",
    "# FILE_SUFFIX = 'en-te'\n",
    "# SRC_LANG = 'te'\n",
    "# TRG_LANG = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93cb7bba",
   "metadata": {
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1631108982946,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "a305918d"
   },
   "outputs": [],
   "source": [
    "src_train_tokens = []\n",
    "trg_train_tokens = []\n",
    "for a, b in dataset_train:\n",
    "    src_train_tokens.append(a.split())\n",
    "    trg_train_tokens.append(b.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fdaa46da",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1631108983252,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "397fc53e"
   },
   "outputs": [],
   "source": [
    "src_train_tokens = list(chain.from_iterable(src_train_tokens))\n",
    "trg_train_tokens = list(chain.from_iterable(trg_train_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2ababeb",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1631108983253,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "e0e0bbf4"
   },
   "outputs": [],
   "source": [
    "# Fix bug in torchtext.vocab.build_vocab_from_iterator\n",
    "def build_vocab_from_iterator_N(iterator, min_freq = 1, specials = None, special_first = True):\n",
    "    \"\"\"\n",
    "    Build a Vocab from an iterator.\n",
    "\n",
    "    Args:\n",
    "        iterator: Iterator used to build Vocab. Must yield list or iterator of tokens.\n",
    "        min_freq: The minimum frequency needed to include a token in the vocabulary.\n",
    "        specials: Special symbols to add. The order of supplied tokens will be preserved.\n",
    "        special_first: Indicates whether to insert symbols at the beginning or at the end.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        torchtext.vocab.Vocab: A `Vocab` object\n",
    "\n",
    "    Examples:\n",
    "        >>> #generating vocab from text file\n",
    "        >>> import io\n",
    "        >>> from torchtext.vocab import build_vocab_from_iterator\n",
    "        >>> def yield_tokens(file_path):\n",
    "        >>>     with io.open(file_path, encoding = 'utf-8') as f:\n",
    "        >>>         for line in f:\n",
    "        >>>             yield line.strip().split()\n",
    "        >>> vocab = build_vocab_from_iterator(yield_tokens_batch(file_path), specials=[\"<unk>\"])\n",
    "    \"\"\"\n",
    "\n",
    "    counter = Counter()\n",
    "    for tokens in iterator:\n",
    "        counter.update([tokens]) # Added brackets. otherwise characters will be updated insted of words\n",
    "\n",
    "    if specials is not None:\n",
    "        for tok in specials:\n",
    "            del counter[tok]\n",
    "\n",
    "    sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[0])\n",
    "    sorted_by_freq_tuples.sort(key=lambda x: x[1], reverse=True)\n",
    "    ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "\n",
    "    if specials is not None:\n",
    "        if special_first:\n",
    "            specials = specials[::-1]\n",
    "        for symbol in specials:\n",
    "            ordered_dict.update({symbol: min_freq})\n",
    "            ordered_dict.move_to_end(symbol, last=not special_first)\n",
    "\n",
    "    word_vocab = torchtext.vocab.vocab(ordered_dict, min_freq=min_freq)\n",
    "    return word_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c84feb9",
   "metadata": {
    "executionInfo": {
     "elapsed": 1820,
     "status": "ok",
     "timestamp": 1631108985585,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "8551b7ec"
   },
   "outputs": [],
   "source": [
    "MIN_FREQ = 2\n",
    "vocab_src = build_vocab_from_iterator_N(src_train_tokens, min_freq=MIN_FREQ, specials=['<pad>','<unk>', '<bos>', '<eos>'], special_first=True)\n",
    "vocab_trg = build_vocab_from_iterator_N(trg_train_tokens, min_freq=MIN_FREQ, specials=['<pad>','<unk>', '<bos>', '<eos>'], special_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0def1b09",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1631108985587,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "8e055964"
   },
   "outputs": [],
   "source": [
    "vocab_src.set_default_index(vocab_src['<unk>'])\n",
    "vocab_trg.set_default_index(vocab_trg['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6981e54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1631108985588,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "b3dce928",
    "outputId": "076434f8-f278-4817-86d6-80972af27755"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9762, 7964)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_src), len(vocab_trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12d7a9fe",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1631108858348,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "158f8f06"
   },
   "outputs": [],
   "source": [
    "# vocab_src.vocab.lookup_tokens(dataset_train[0][0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f452234f",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1631108858349,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "e297164a"
   },
   "outputs": [],
   "source": [
    "v_t = vocab_trg.get_itos()\n",
    "v_s = vocab_src.get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ecb3722",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1631108858349,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "46dbb04b"
   },
   "outputs": [],
   "source": [
    "# Function to perform padding\n",
    "\n",
    "# pad_indx = vocab_src.word2indx['<pad>']\n",
    "pad_indx = vocab_src['<pad>']\n",
    "\n",
    "def collate_by_padding(batch):\n",
    "    inputs = [None]*len(batch)\n",
    "    targets = [None]*len(batch)\n",
    "    inputs_len = [None]*len(batch)\n",
    "    targets_len = [None]*len(batch)\n",
    "\n",
    "    for i,(inp, targ) in enumerate(tuple(batch)):\n",
    "        inp = vocab_src(inp.split()+['<eos>'])\n",
    "        targ = vocab_trg(['<bos>']+targ.split()+['<eos>'])\n",
    "        inputs[i] = torch.IntTensor(inp)\n",
    "        targets[i] = torch.IntTensor(targ)\n",
    "        \n",
    "        inputs_len[i] = len(inp)\n",
    "        targets_len[i] = len(targ)\n",
    "        \n",
    "\n",
    "    max_length_inputs = max(inputs_len)\n",
    "    max_length_targets = max(targets_len)\n",
    "    \n",
    "    for i in range(len(batch)):\n",
    "        inputs[i] = torch.cat((inputs[i], torch.IntTensor([pad_indx]*(max_length_inputs - inputs_len[i]))), dim=-1)\n",
    "        targets[i] = torch.cat((targets[i], torch.IntTensor([pad_indx]*(max_length_targets - targets_len[i]))), dim=-1)\n",
    "        \n",
    "    return torch.stack(inputs), torch.stack(targets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f89ea4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 490,
     "status": "ok",
     "timestamp": 1631108972440,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "d9f91f00",
    "outputId": "9c8668ee-95d5-46d6-e645-750dc1303c07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9762, 7964)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_src), len(vocab_trg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44de52f",
   "metadata": {
    "id": "7c21227b"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054737a3",
   "metadata": {
    "id": "jH4NmY5b-hCD"
   },
   "source": [
    "Implemnetation of the transformer architecture as detailed in \"Attention Is All You Need\" by Vaswani et al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4725c37f",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1631108859562,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "_AGmWNUE-kfD"
   },
   "outputs": [],
   "source": [
    "NEG_INF = -1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5246c0c2",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1631108860023,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "LMJgF_HW-lsM"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    '''\n",
    "    Scaled dot-product attention \n",
    "    '''\n",
    "    def __init__(self, projection_size_qk, projection_size_v, model_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.d_k = projection_size_qk\n",
    "        self.d_v = projection_size_v\n",
    "        self.d_model = model_dim\n",
    "#         self.projection_matrix_Q = torch.nn.Parameter(torch.rand(self.d_model, self.d_k))\n",
    "#         self.projection_matrix_K = torch.nn.Parameter(torch.rand(self.d_model, self.d_k))\n",
    "#         self.projection_matrix_V = torch.nn.Parameter(torch.rand(self.d_model, self.d_v))\n",
    "        self.linear_Q = nn.Linear(self.d_model, self.d_k, bias=False)\n",
    "        self.linear_K = nn.Linear(self.d_model, self.d_k, bias=False)\n",
    "        self.linear_V = nn.Linear(self.d_model, self.d_v, bias=False)\n",
    "        \n",
    "#         self.inv_sqrt_d_k = projection_size_qk**(-0.5)\n",
    "        self.inv_sqrt_d_k = model_dim**(-0.5)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "#         return self._attention(Q@self.projection_matrix_Q, K@self.projection_matrix_K, V@self.projection_matrix_V, mask)\n",
    "        return self._attention(self.linear_Q(Q), self.linear_K(K), self.linear_V(V), mask)\n",
    "        \n",
    "    def _attention(self, Q, K, V, mask):\n",
    "        scores = Q@ K.transpose(1,2) * self.inv_sqrt_d_k\n",
    "        if mask is None:           \n",
    "            attn_wts = F.softmax(scores, dim=-1)\n",
    "        else:\n",
    "            attn_wts = F.softmax(scores.masked_fill(mask, NEG_INF), dim=-1)\n",
    "        return (attn_wts@V).squeeze(1), attn_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5b17e83",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1631108865250,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "vLuzWMI7-yVS"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    '''\n",
    "    Multi-headed attention\n",
    "    '''\n",
    "    def __init__(self, n_heads, projection_size_qk, projection_size_v, model_dim):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = projection_size_qk\n",
    "        self.d_v = projection_size_v\n",
    "        self.d_model = model_dim        \n",
    "        self.attention_heads = nn.ModuleList([Attention(projection_size_qk, projection_size_v, model_dim) for i in range(n_heads)])\n",
    "        self.linear_O = nn.Linear(projection_size_v*n_heads, model_dim, bias=False)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None, return_attention_weights = False):\n",
    "        if not return_attention_weights:\n",
    "            mha = torch.zeros(Q.shape[0],Q.shape[1], self.n_heads*self.d_v, device=Q.device)\n",
    "            for i,attention_head in enumerate(self.attention_heads):\n",
    "                attn_vec, attn_wts = attention_head(Q, K, V, mask)\n",
    "                mha[:,:,i*self.d_v: (1+i)*self.d_v] = attn_vec\n",
    "            return self.linear_O(mha), None\n",
    "    \n",
    "        else:\n",
    "            attn_wts_list = []\n",
    "            mha = torch.zeros(Q.shape[0],Q.shape[1], self.n_heads*self.d_v)\n",
    "            for i,attention_head in enumerate(self.attention_heads):\n",
    "                attn_vec, attn_wts = attention_head(Q, K, V, mask)\n",
    "                mha[:,:,i*self.d_v: (1+i)*self.d_v] = attn_vec\n",
    "                attn_wts_list.append(attn_wts)\n",
    "                \n",
    "            return self.linear_O(mha), attn_wts_list\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6232ea59",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1631108865582,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "AH2iO_tu-3jR"
   },
   "outputs": [],
   "source": [
    "# class PositionalEmbedding(nn.Module):\n",
    "#     '''\n",
    "#     Sin and Cos based positional encodings\n",
    "#     '''\n",
    "    \n",
    "#     def __init__(self,model_dim, max_seq_len):\n",
    "#         super(PositionalEmbedding, self).__init__()\n",
    "#         self.reusable_factor = torch.Tensor([10000**(-2*torch.floor(i/2)/model_dim) for i in torch.arange(0,model_dim)])\n",
    "#         self.max_seq_len = max_seq_len\n",
    "#         self.model_dim = model_dim\n",
    "        \n",
    "#     def forward(self, emb_shape):\n",
    "#         pos_enc  = torch.zeros(emb_shape)\n",
    "#         reusable_factor = self.reusable_factor.unsqueeze(0).unsqueeze(1).expand(emb_shape[0],emb_shape[1],-1)\n",
    "#         pos = torch.arange(0, emb_shape[1]).unsqueeze(0).unsqueeze(2).expand(emb_shape[0],-1,emb_shape[2])\n",
    "        \n",
    "#         pos_enc[:, :, 0::2] = torch.sin(pos[:,:emb_shape[1],0:emb_shape[2]:2]*reusable_factor[:,:emb_shape[1],0:emb_shape[2]:2])\n",
    "#         pos_enc[:, :, 1::2] = torch.cos(pos[:,:emb_shape[1],1:emb_shape[2]:2]*reusable_factor[:,:emb_shape[1],1:emb_shape[2]:2])\n",
    "#         return pos_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "685cfcd5",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1631108866783,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "0xnhSqT8-5Cy"
   },
   "outputs": [],
   "source": [
    "def positional_encoding_matrix(batch_size, model_dim, max_seq_len):\n",
    "    '''\n",
    "    computes and returns a positional embedding matrix.    \n",
    "    '''\n",
    "    \n",
    "    reusable_factor = torch.Tensor([10000**(-2*torch.floor(i/2)/model_dim) for i in torch.arange(0,model_dim)])\n",
    "    pos_enc  = torch.zeros((batch_size, max_seq_len, model_dim))\n",
    "    reusable_factor = reusable_factor.unsqueeze(0).unsqueeze(1).expand(batch_size,max_seq_len,-1)\n",
    "    pos = torch.arange(0, max_seq_len).unsqueeze(0).unsqueeze(2).expand(batch_size,-1,model_dim)\n",
    "\n",
    "    pos_enc[:, :, 0::2] = torch.sin(pos[:,:max_seq_len,0:model_dim:2]*reusable_factor[:,:max_seq_len,0:model_dim:2])\n",
    "    pos_enc[:, :, 1::2] = torch.cos(pos[:,:max_seq_len,1:model_dim:2]*reusable_factor[:,:max_seq_len,1:model_dim:2])\n",
    "    return pos_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "091752fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1631108867353,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "GHCSE_D--6qE",
    "outputId": "a480ab80-f60d-472a-dc20-bad1f0098149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa7e08d7a50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAACuCAYAAAD55TMFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deZRc1XWvf7uGniV1t4ZWSy1ooQGBsJBAxgweMNjMNtgmYGIcTLBl8kxiEsfP2H4rIW/xXhybAA44xkogQGyD/QzEAgMxFtiAGSUhQAMakASaWmr1PFV3ddV5f3QhaZ99pbrVqi5VS79vLRbadfe599SpKzh96+u9xTkHQgghhBASnsjhngAhhBBCyGiDGyhCCCGEkBzhBooQQgghJEe4gSKEEEIIyRFuoAghhBBCcoQbKEIIIYSQHCn4BkpELhCRdSKyUURuKvT1jyREZJqIPCsia0RktYh8PfN6rYg8LSIbMv+uOdxzHa2ISFREXheRxzPxdBF5JXP//kJESg73HEcjIlItIr8SkbdFZK2InMH7Nj+IyF9n/nuwSkQeFJEy3rfDR0TuFZHdIrJqv9cC71UZ4l8y6/ymiJxy+GZe/BxgbX+Q+e/CmyLyqIhU73fs25m1XSci5x+eWe+joBsoEYkC+BGACwGcCOAqETmxkHM4whgE8A3n3IkATgfwtcx63gRgqXNuFoClmZgMj68DWLtf/E8AbnfOzQTQBuC6wzKr0c8PATzlnJsD4GQMrTHv20NERKYC+CsAC51zJwGIAvg8eN8eCvcBuMB77UD36oUAZmX+WQTgxwWa42jlPti1fRrASc65eQDWA/g2AGT+3/Z5AHMzY/41s6c4bBT6CdRpADY65zY55wYAPATg0gLP4YjBObfTObci8+cuDP1PaCqG1vT+TNr9AC47PDMc3YhIA4CLAfx7JhYA5wD4VSaFazsMRGQcgI8CuAcAnHMDzrl28L7NFzEA5SISA1ABYCd43w4b59xzAFq9lw90r14K4AE3xMsAqkWkvjAzHX0Era1z7rfOucFM+DKAhsyfLwXwkHOu3zm3GcBGDO0pDhuF3kBNBbB1v3hb5jVyiIhII4AFAF4BUOec25k51ASg7jBNa7RzB4D/CSCdiccDaN/vLzfv3+ExHUAzgP/IfD367yJSCd63h4xzbjuAWwG8h6GNUweA5eB9m28OdK/y/3H55c8BPJn5c9GtLSXyIwARqQLwMIAbnXOd+x9zQ7162K8nR0TkEgC7nXPLD/dcjkBiAE4B8GPn3AIAPfC+ruN9OzwyLs6lGNqkTgFQCfsVCckjvFdHBhH5LoY0lZ8d7rkciEJvoLYDmLZf3JB5jQwTEYljaPP0M+fcI5mXd73/2Djz792Ha36jmLMAfFpEtmDoq+ZzMOTtVGe+GgF4/w6XbQC2OedeycS/wtCGivftofMJAJudc83OuSSARzB0L/O+zS8Hulf5/7g8ICJfAnAJgC+4fQ17i25tC72Beg3ArMxvhJRgSAhbUuA5HDFknJx7AKx1zt2236ElAK7J/PkaAL8u9NxGO865bzvnGpxzjRi6T59xzn0BwLMALs+kcW2HgXOuCcBWETk+89K5ANaA920+eA/A6SJSkfnvw/try/s2vxzoXl0C4M8yv413OoCO/b7qIyEQkQswpE582jnXu9+hJQA+LyKlIjIdQ6L+q4djju8j+zZ3BbqgyEUYckuiAO51zv2fgk7gCEJEPgzgeQBvYZ+n8x0MeVC/BHAMgHcBXOGc8yVIEhIRORvA3zrnLhGR4zD0RKoWwOsArnbO9R/O+Y1GRGQ+huT8EgCbAFyLoR/oeN8eIiLyDwCuxNDXH68D+DKGXBHet8NARB4EcDaACQB2Afh7AP+FgHs1s2m9C0Nfm/YCuNY5t+xwzHs0cIC1/TaAUgAtmbSXnXPXZ/K/iyEvahBDysqT/jkLScE3UIQQQgghox1K5IQQQgghOcINFCGEEEJIjnADRQghhBCSI9xAEUIIIYTkCDdQhBBCCCE5clg2UCKy6HBc92iAazuycH1HDq7tyMG1HTm4tiNHsa/tIW2gROQCEVknIhtFJJfO6UW9KKMcru3IwvUdObi2IwfXduTg2o4cRb22w95AiUgUwI8AXAjgRABXiciJ+ZoYIYQQQkixMuxCmiJyBoCbnXPnZ+JvA4Bz7h8PNCZaVeliNbVI9fQgWlmJD9Q2m5y3Wieq2M/xj+crp1BzGenrvL+2xTCXQl+nEHM50L2bj+vkOpewOcV8nf1zwq7tSM2lWO+5fFwnn2t7qHMZjdc5WE6h/392NP235VDWNl9zWf5m/x7nnE3EoW2gLgdwgXPuy5n4iwA+5Jy74UBjSqdNc1O+cePe+J3P321yZjx0vYr9HP94vnIKNRe+55G7TjHNZTjXKaa58D2PvrnwPY/cdYppLkfj37PD+Z6j9RuXO+cWmkQUQCIXkUUiskxElqV6ekb6coQQQgghI07sEMZuBzBtv7gh85rCObcYwGIAOGFeqXvgM/+y99gN2z9iTnr7px5Q8Q9aZ6j4mxc8ZsY81FWj4qvPfd7kLO2Lqvj8j6xU8cp+21fz1NM2qPidZLeKZ83fasZsG9Q59SfuVvGelN1EVs/S/VI70n0qrpjeacb0pgdUXDLNnrffJVUcrdfnTbqUGYNJ/QfNceP1dQEg5dIqTtckD3ocANJjB+219z9eFTA3P6cyRE6FvbbJKT94Tros+zlcafYnua4kRE784DnZjgOAix16jose9HDonFA/omXLycc5wuRIiHMUKudIu04xzeVofM/FNJfR9p4PwqE8gXoNwCwRmS4iJQA+D2DJoU2HEEIIIaT4GfYTKOfcoIjcAOC/AUQB3OucW523mRFCCCGEFCmH8hUenHNPAHgiT3MhhBBCCBkVsJULIYQQQkiOHNITqFyJI4266D4JedkdC0zOD7//kopvuu98Fa/52r+aMdOX6GKlqy+5y+R86LUvqfg3py5W8Q2bLzdjvjPtNyq+c8/ZKv5Kg5XVH+2aq+Irpy1X8R/66s2Y8xveVvEbA+UqPn3Ku2bMxkEtNs+dvNPkbBvUQvj0SS0q3pPSUjkATJ7QoeKOdELF1TVWVu92+jqV4/SYfmeF8dKx/V6OFs9jVToGrNAeqbTn9YV1KR886PGhyaQPnlMSQiKPh8gJI3dnk8jzIIgDGPrS/aDHQ5wjEmIuechxIUTPvOQcQXIrIWTk4RMoQgghhJAc4QaKEEIIISRHuIEihBBCCMmRgjpQ67rq8NFn9nV6mfXzV0zO9X+li2tOv3eTip+6ttSMmfkz7ct0X2z9mbIl41R8zIeqVLz+98eZMad/RYsiV70+X8W3XPCCGfPRFReq+P+dfI+Kv/XeZWbMX0/9rYqXdJyi4nOr15gxL/bqAqNn1mwyOW8NTFbxvBpd53TTYIUZM6daF/7cldJ77MZqXfQTAFpT2k2qG9ul4o60Lb5ZM6ZXxb1p/ZlVVWqPCrCeVFm5Pa/vW8XLdDwIW3wz6uWkoZ2cSKkdY1yrkiweFWBcqsCcbO5RKDcpe4rLcp4w7lLBClyGmYscek7BXKt8QdeKkMMKn0ARQgghhOQIN1CEEEIIITnCDRQhhBBCSI4U1IEqa0phzvf3+TGDZ8wzOcv/Q3s5dW2vq/h/vHC1GTPrhRUq/u6O80zOpKc2q/ip72qXatrvbE2kPX+uax5N+GNcxVUXlZkxva+PV/GMhdq1Wr6u0Yw5ebp2ef5y6/EqXnSyda18l8r3qADrUp1auUXFbyWmwWdu1Q4Vb0hOVPGMqj1mzI6U/swaq7Qn1Zq2RYfqK3WD5Pa09oFqK7UjBQBdae0qja0I8qR0TkWZXtugBsqlpcmD5sRK7BjfpYp4Ob5HBQCRePbmxxLP4kkF1HgyOfmo4ZQHjwoI6VLlw9MJ86Ng1uvkybUKQTZPqmAeVRjyVfuKkCMMPoEihBBCCMkRbqAIIYQQQnKEGyhCCCGEkBw5JAdKRLYA6AKQAjDonFuYj0kRQgghhBQz+ZDIP+6cs2ZxAK5/AOl39jXG3fULW7xyyhd1Qcg9V+mGw40/t0UyY8c0qPj5/24wOcfu1E2K/27dp1U8/rW1ZswDHR9Q8cSX9dt8c8BKzJNWaIm51ysiOXZViRnjy+idG2pUfMypurkwALyxVb/HWY1Wgn91z7Eq/sKsl1V8565zzZjPjV+m4hW9jSqeU26bFr8zMEnF0yv0Om0fHGvGTCnXEnlrWq9LXbkuxgkAXZ5ZW1Nm33OPJ1SPKdNNixMBEnmFL5F7grgvmQNWNI/HfYncFsmMxtJeTpBofvAciWVvWoxYgQp2hhGqw8jo2ZoJ50NED5OTt0bBhZHRi6qoZxiKaS6E5AF+hUcIIYQQkiOHuoFyAH4rIstFZFE+JkQIIYQQUuwc6ld4H3bObReRSQCeFpG3nXPP7Z+Q2VgtAoAy2N5rhBBCCCGjjUPaQDnntmf+vVtEHgVwGoDnvJzFABYDQEXdNNf0+VP3HvvjwtvMOa8ovVjF069br+KOj7abMe9940MqbnzM+jMyb46KE8/U6vcyqAttAsDdqz6s4uM26Ka+/9l6hhkz5o0mFb8+oJd4/Crt5ABAR1q7POPWa1kgLrYQpWzRXtT4j1lP6t3tE1Q8bY52Yd5qqTdjvjlZF8F8oOtMFZ85eYMZ82z3CSqeUbpLxVuTurgoAEwr09dpSmlPqr6sw4xpTWlXbEJZt8npSuuHqtWeJ9XrrHtSVao/k37PGaooCXKgdE5JfNA7bl2reEn2nEj04C5VJMCBMp5UCH/JzzGeVL6aCYfygQ7xOABXoOuEIh/nyVPBzmyMOkeqmOZLjnqG/RWeiFSKyJj3/wzgPACr8jUxQgghhJBi5VCeQNUBeFRE3j/Pz51zT+VlVoQQQgghRcywN1DOuU0ATs7jXAghhBBCRgUsY0AIIYQQkiP5KKQZmvETO/Cl65/YG/+ub4LJ2fql41W8bPoPVfzZuk+ZMad97k0Vb7u1x57321r4PuYJLaO7k/V1AaD8pSr9guj95qNvn2TGzHjvLRX/olUL7uXrtGANAK/3V6q4eoMuvtmW6jVjxnrOe1TsXji+TRenHBvREvauXePMmLp5+jwb2iaqeEqDFfTXddep+ONVuijp77rmmjEnlO9Q8faklvonl1qJfHdqjIonlliJvCNdquLxpfpe6EpbIX9ciS6ImvBE88oS/XkAQNITt8s90dyXzAGgJJa92KZfkDPlzSUaDZLIDy6aBxXslIDz6ON2zGETzfMkF2cVzfNWSDNPOVnPcRSK5mEYbfMloxY+gSKEEEIIyRFuoAghhBBCcoQbKEIIIYSQHCmoAzUp2o+/rN7XLPgDd99gcj579fMqfimhnZbtl9sGxL9o0AU5rxh/scmZe9E6FXd8TztQO7xinAAw9ffa95ET9LUrltvK6hLRX8A/tVEXmTxupy7GCQC/6dC/zFi2qVnFa5LaXQKAsZu1l+MX4wSAqq069j2p+M6Axsai17tlj+cdRaxgsKVD+0u+J7Wpx7punxizWsXZinECQLPXlHhSifWxWtLaJ6uN+w6Ufc9jS/Ta9XjFOCvj1oHyPanyuN+Q2PoppabYpvWQYlHfX9JxLGaLb/qeVCRy8HMA1nEynlQIvylrMc6Q58n6Y1w+imSGyMlLMc58kbeinvSkDKNprqSo4RMoQgghhJAc4QaKEEIIISRHuIEihBBCCMmRgjpQGxLVuHjdvjpOjXeuNjm3/IWuozT9vxapeMGf2Ga2zSntlrSdN8vk3H3MrSr+atl5Kq46xzo3cud2Fe++ZoGKJ63Q9YMAINI4TcWx1bqWlEtZh+V3W3UNqrqdusjTHzw/CADK3tMO1+ak3QuP2abXpTetXZ6KnVYG8D2pSLN2hqoi2pECgD1t2pOq9aayrbvajJkY1W7Se33aozqrUjeRBoBXe2eouD5uG0u3DOr1ronrGlrtaeutVce1A9Xl4ioeG7efczZPynekAKAs5jlQITypFHKvAxULaDjs43tS5nhAHajheFJ+zrA8qSOtaXHYnIKcozCOFDDKPClCQsAnUIQQQgghOcINFCGEEEJIjnADRQghhBCSI1k3UCJyr4jsFpFV+71WKyJPi8iGzL9rRnaahBBCCCHFQxiJ/D4AdwF4YL/XbgKw1Dn3PRG5KRN/K9uJ3K44ErdO2RtXVu0wOYs7pqh4zk90scR7Hv+1GXPJ6j9TccunbFHJ+mi5ipOnzVHxLbPvN2O+3z9PxW1n9au47hGvUiWAzo/pYpvjV2tpPDpJN+cFgK4NWrKe1K+v82zzbDMm3qSLbS5PHGtyyrdrUXtnSovOlU1WaE86/Vp5szY/42Kb8aZbtGg+JqLj5k6vKTOA2oi+zo4e3dh4fJ1tCN3Ur3Pmlb9nctb116t4QkzfP+0pK5H7onlXWhcuDZLI+51eh4qYXttkgJtbFtPFNgcCRPOSqF4Xv9hmPBpQSDOLaO4X2hzK8Qtpeg2Js0jmACCRLMU4A3ICySaa503cLpKmxWHOk7dCmvk4R+FE86KBwjsJQdYnUM655wC0ei9fCuD9Hcf9AC7L87wIIYQQQoqW4TpQdc65nZk/NwGoy9N8CCGEEEKKnkOWyJ1zDgh4dp9BRBaJyDIRWZYcsF/LEEIIIYSMNoZbSHOXiNQ753aKSD2A3QdKdM4tBrAYAMZKrSt94rW9x96+/XSTv/FXx6i48Y2XVBxUfDD5oH4Aduv/sj7TnW26uObWc3VByHPLrVty23TtFf3pvNdU/Fqz9YF2nzJTxTPv167S4EzteAHAuPX6C/dIhfZ01r9rH/DN7tqm4hc7ZpqcSFOLit9O6qa+FTu1awUAbWnt+5Tvzu4/lLbqdSgVXYgy0W6bIY+J6Ftvd7f2pGojtoFvU0IX7Bwf7TY5e5I659jKPSr2GxIDwLioV0gzrX25MbGAQppesc0xMb2WCWfvjTCelGlK7PlLJQHNhNNeTixEM+FsnlSQu+SfJ4zfFConm28S8GOe8aTCuFbFUrwyXxTTXPLAqCu0OdrmS/LOcJ9ALQFwTebP1wCwZjchhBBCyBFKmDIGDwJ4CcDxIrJNRK4D8D0AnxSRDQA+kYkJIYQQQo4Ksn6F55y76gCHzs3zXAghhBBCRgUFbSbsxlWg/yMf3Bs/fNkPTc53z75cxb3nL1Txn22YasZM+PUaFX/6H3tNzvSnP6HiBR/bqOLNSevTtJ4+WcWLan+q4uUVuiExAIxfoHUw9791Q+KWs3VDYgCoWa/9GZminafyzbquUhArdjWY1+radFPiN3q10xXfrWskAcCOQX1LVDQfvCExAJS2mJcU0XZ7m/meVFe35x1FrGCwu1f7TdUR63Dt7vdyxuh7Yf2grhMF2KbEnSntbI2JWgfK96QqPQeqx9n3XOHVgUo4+wC4NOo3HPaPB9Tu8rzAuOdJ+XWiAFvnyfebgpoWZztHEF5v6sBaUVn9pUI18M1XvaN81IoqlF+Tt3pThakVNeo8KXJEw1YuhBBCCCE5wg0UIYQQQkiOcANFCCGEEJIj3EARQgghhORIQSXySF0SFX+7T6qeEPUVWSC1Y5eKm2/XhQ9LfqkLbQJAXeJ1Fb/ab8/buERLjjdf9JiK/2/T+WbMrrP0mGNiXlPc2Y1mzJcbn1HxLxNaRG87yYq3k5/SxTZ752iJfOzmgEKI4/S6tG+3BSL9psQrOqbphJY2M2Z9cpKKS5u1QN0aIJGXtfpFGXVc0m7NT78pcapTS+UVnmQOAG29vmhuheqW/koVj43o+e9J2sbGJ5TpptY7kjUq9gttAkBPWhdirYr6hTTt/Mu9+z0Z8PNLmZ/jubm+ZA7YIph+w2G/ITFgi236onkkQOz2r+PnBBXslBBycbZim6EaEnu3mCm0CeSnmXAY8iC056UhcdgcMnJw/Y9o+ASKEEIIISRHuIEihBBCCMkRbqAIIYQQQnKkoA7UzLJ2PDb78X3xb79ucib/iXZHnlh4q4qv/+pnzJjOi09W8Q1rppmc8c+tVvG8El0s8dnnP2DGfPzDq1S8ekC7MHsWjDNjPlX1joofHjtbxdNP2GnGpJp08c32T+n5T1hpC4OibqIKK7YGfJQR7Rm93azdqobODWbI6j5dkDPaqguM7khp9wcAylq1c9PntCdVqutUBhLr9BsS2/fT262vXRHQhbalTzdiHucV22wd0McBYExEf66tg3oNji3VDYkBoCut7x/fgepN23Xyi20GNRwu8xynAa/Ypu83AbbYZtwUybTEshTKjAYUyfQdpyBPykfCFNv0PkZTbDOU65MHZyhf1znSYLHNkWM0zZUY+ASKEEIIISRHuIEihBBCCMkRbqAIIYQQQnIk6wZKRO4Vkd0ismq/124Wke0isjLzz0UjO01CCCGEkOIhjER+H4C7ADzgvX67c+5Wm35gdqfK8MO2mXvjE77faXLSP9LCtL/DS7d3mDFtf6pF59LHJ9iLp7eq0C+22bDUyrlfv/x3Kr5j1ydU3HKqFWQnRXUhRzd9qoqvnPoHM+bhfl28smO2nsuUx1rMGL/YZtU2K2hGq/Rcepq8uSVtUczVnfX6hXb9GW1J2rUtbdHFKtvTWoQubbfr5Bc6jHdqmzIqdm+f7slebLOzT8vdlZ7E3B4gkfvFNtsGdc5J5fo4YIttjonqHL/QJgBURPR6D6fYpl9oE8hebNMvgAlkL7YZJJFnK7YZdJ18FNsMU0gzL8U281W8Mgx5ENrzUmyTEjMhwybrEyjn3HMAWgswF0IIIYSQUcGhOFA3iMibma/4ag6UJCKLRGSZiCzrbrVPPAghhBBCRhvD3UD9GMAMAPMB7ATwzwdKdM4tds4tdM4trKotGeblCCGEEEKKh2EV0nTO7e34KyL/BuDxg6TvpaV5LP7z7gv2xnWblpucX83WjtCZy76i4trzbDPYB075kYr/7m8+Z3J6P3aSim/eUqviipfWmzF+sc3fLZ+r4gXzNpkxm5Pax2qfq4ttXlBpr/NoRaOK62bpwo3pXbrZMAB0XqCLPdas7zc5mDReheU7vY87oBDlO63acarr2qzijV5zZACItmtvbU9Kuz1l7dYv63fa0ynpMin2Ol268KTfkBgA+noPXmyzPaEbEgPAGM9N6kj6TYttM+GO1BQV18d1tdCetP1hoSKqrxNUbLM86ntS+j36hTaB7MU2rTWVvdhmtkKbABAx57Bj8lFsM+A2HZlim/lqzstim8M8BwttktHFsJ5Aicj+pvFnAKw6UC4hhBBCyJFG1idQIvIggLMBTBCRbQD+HsDZIjIfgAOwBcBXR3COhBBCCCFFRdYNlHPuqoCX7xmBuRBCCCGEjAoK2kw41tyLup8s2xs3Xb/Q5KxJvqDi2p9o52nb1dYBmVeiPZHBd7eanHe/qZ2V0mcbVXxMx0tmzLZB7TPVvai/8Vx03nNmzIMdp6q45ST9hfsxMetwyVTtFV0wZa2KX0xYn6Zruo7rnrX1sZL11SquaPLq+JRbH6h9j57fpH7tVm3o1TWrAEA69TptT2nvq6TdWjjdTr9W0unXFLJeTLxbr2WQA5Xq0bd0mZfTlQiozyTaGeoY8GtJWb+sY1Cv3ewy3SS6eXCsGVPl1YoKVQfKc6BKI/b+92tFlUT8OlBmiPGk/BpOgc2EvZxYiEbBYWpF2WbCuddnylZLKug6NsG+dNhqRRWTp1NMczka4foXLWzlQgghhBCSI9xAEUIIIYTkCDdQhBBCCCE5wg0UIYQQQkiOFFQil9ISRGY07o2/dP0TJufKZ/5CxbOffE3F/37Xm2bMPzTPV3H0+Jkm56sfe0bFS68/S4+ZPcOMuadNy8O1L+9S8UfLbPXHv31Ti/HlJ+oCi91p25i2b4YueHnh2DdU/GLkdDMGjT06brbtCrsXTlRx5U4tDkdqtGQOAPFmKzbvzzsdtplwZdduFW8Z0NeNdtj33JLSZmRpp5Z1B2GLb8a7zUuGSO/Bi232Bgj5ZZ6k2ZX0JHKxEnzn4MFF880pfRwAamL6MxtOw2G/UTAAJL1CmiWmkKa1UKOi19tfbb/Q5lCOL5q7gx4HbLHNILIV24wMQ9w2hTaBEIU0C1gAMx/XykfD4UIKyqOo2CYhYeATKEIIIYSQHOEGihBCCCEkR7iBIoQQQgjJkYI6UInJUbz9rX2FGh+rts14n/yJdkkiJ81R8dnlK82Y63/6ERXHP2WvfWPtGhX/frn2jpquXWDGPPDmh1Q88x197VKxy5derotIfu4K3Rz5lf5KM6ZttvZcTop7rsl43fgYAE6Ztk2fo6PT5HQ36P3x1Ge0RJSeoOcKAGW7taggMf0em9rGmDHT+95T8ZaE9qQiXZ6vBaA5XaHieKd2exLOuj7x7uz+Q7RXzz8G7UAl+6zjVSZ6nbr6vYbEAcUrrSflNwq2rlW9tKk4kQ6YS0T7Vr4DVe45UoAttmkLaVr5xPekfFMpsJBmlhy/0CZgtZfghsOej+WfJ8B78c8jIZoWZ3NwshbaDHGO0DmkqBl1DYdH23yPEPgEihBCCCEkR7iBIoQQQgjJEW6gCCGEEEJyJKsDJSLTADwAoA6AA7DYOfdDEakF8AsAjQC2ALjCOdd2oPMAwPFjduHxj//L3vjidVfapFffUuG6u7SHdFvrcWbIcQ81qzj9o16T05zSbpVLaYcica6t6TRuqfZ9IqXajVk5YN2YSSu0w/K5ryxX8Z27zjVjOmdrH6Uiov0ZN8XWXjqnVrtVD6dtk9+eBn3eaLNuONw7p86MKW/2Gg5XaFcp2WrrGyGtr7O5R8/X9djPo2lQ+1fxTu32dKWD6kBlbzgc69EyQNTzm1zCNiD2Xbaefr3+ZQEOTvdgqZejP3e/2TAAVJbr97gjaX04UwfKc6mCmgkPwG847NeBsj8n+Z5U0vnH7fpnazgcVAcqTE429yhbnSggpJqU7TzDbBRc1A2Hs+RkrROVp+sQciQS5gnUIIBvOOdOBHA6gK+JyIkAbgKw1Dk3C8DSTEwIIYQQcsSTdQPlnNvpnFuR+XMXgLUApgK4FMD9mbT7AVw2UpMkhBBCCCkmcnKgRKQRwAIArwCoc87tzBxqwtBXfEFjFonIMhFZ1h+Zaw8AABB4SURBVNqava0DIYQQQkixE3oDJSJVAB4GcKNzThUdcs45IKj5FOCcW+ycW+icW1hbS2edEEIIIaOfUIU0RSSOoc3Tz5xzj2Re3iUi9c65nSJSD2D3gc8wRBIR7Ertk2ITP5hiJ3S2fpB19wX3qvhrD3/ZjDlu7UsqvnPGH03O/9zqVdec36DCv/vA42bM/bdcqGI3VzccvmePGYLKt3ao+IS4LoT47MbZZkz9TC3B70l5TWen2+KVZ5W/o+JH4g0mp6JBF850bVoi75lsx1Tu0nKxjBur4pJWK2H7bOvSTYpreneYnB3JGhVHu7Xk35G21ynpCdFw2Prqikiv3cT7DYf7E/ozKwuwnLsG/GKbWiLvGbSNgv2Gw0HFNv2Gw6aZcIBE7hfk9HP8ZsOAlcRTngUcVEjTX+1oCAHZbzgcRLaGw2EKXEqIufjnMQ2HQ8nSBZKuj8amufkS0Qu0dqOu2CbJO1kfCYmIALgHwFrn3G37HVoC4JrMn68B8Ov8T48QQgghpPgI8wTqLABfBPCWiLzfy+Q7AL4H4Jcich2AdwFcMTJTJIQQQggpLrJuoJxzL+DAD1dtUSNCCCGEkCOcgjYT3tQ2CVc+8ld74xlPvmxzfj5fxR8vT6h4xkO2aS4WzNU5sRUmZeWTJ6g44m39Pldlhab71mrPqGnRqSpev1pfFwBmbbfX3p/SVbbA4oVXaYdrRb92iDoa7cc0Paa9nUi1bQw8r067Ry3d2q/prbf74tpVWiJKj9cOVFmLHeM3HG7t0AUixyW0+wMAWxO6QbL09Om5pu06xbu0hdObTpqcWM/B/YdYn51/xPv5YLBfv594wM8PPQN+sU09t55B6zf5xTa7UrYoaUNJqz5P2nOtonYtk6aQpr6O32wYAGJ+sU3Pk4oNp5mwGRGu4bDvUvmNgoMcqWwNh4OaFmdzY4bjUZEc4NodXrj+eYe/FkcIIYQQkiPcQBFCCCGE5Ag3UIQQQgghOcINFCGEEEJIjhRUIi/bNYDjb3tvb9xz8QdNzm/OukPF12y5RMXu9dVmzDs/OEPF93XaAp3HPt6u4q7vaTm9I61jAHBJXZCw90wtYY99ScvSACAxXdRwbVILvRNW2UKIF455U8X3t5yl4u5GK8RWRLSk7OrGm5yzanRB0SVpndM32Z432tKlc2ZOVHFpqxVtIxUVKk52eEUk07bg5dY+PRfXo+X15kEtrwNArMcrVuns/OO9en4pLycaIJFHRf8c4RKelC32r0kiqV8r8wTk7oBCmr5E3peKZ81pTVd5x4MKaep7wS+kOQArkZdmKaRZElCwM+l99L5obsRuBBfk9Mkmb4cRtyMhCnbmxaEdRiFN/x4MdZ68FZU8xOP5ug4hRyB8AkUIIYQQkiPcQBFCCCGE5Ag3UIQQQgghOVJQBwrpNFzvvoKJVd/cZlJqvS3d+nvnqHjSiS1mzA0XPaniW168xOTMXrlM58zS3tEdLaebMdFZ01V83UkvqnjpXdpVAoDIcceo+NGOU1RcuVY3DgaAEzwV5pn3dMPhqkbdBBgAuj1nK9FgGw5/sHyTipdEJqk4Otl23nUdngM1Uftk5S3WZ5Ix2tOJt2dvONzUox2nyj7di7pp0BYGjXQPqLgrHdAY2HOg/IbDMV2vM5BIQp83GiDh9PfrD823mfoGg/wm7RV1pwI8qYh+j37DYb/ZMJC94XBQIc34MAppmobD4jlQZoQtkpnyG/jCNhz2c7I1Gwby1HA44Bym4XAYCtUIuGBNc4uosXE+XKtiej9kVMMnUIQQQgghOcINFCGEEEJIjmTdQInINBF5VkTWiMhqEfl65vWbRWS7iKzM/HPRyE+XEEIIIeTwE8aBGgTwDefcChEZA2C5iDydOXa7c+7WsBfrn1SGzV/d19R31ay7TM5Zb1yj4okPvqHiTTedbMbcWLNFxY88ZveFscl1Kj67XHsV1z6ta0kBwMQztDtybfVKFf9hTYMZ037+8Sr+ry3zVFy3dbMZ49d06l+v/aBPnvu6GbMxqWWArgb7Uc6K6ZpC0bHaVTpukvXJ0n7D4Ul6Lce8ayUiN1bXwypp90SFiHVwWrp17aiKAT3XnQO6oTIARHq199XlrGcU69Wfa9JpMycayoHS848F1FEaHNCvlXm1pHqTdm6lXsPhMHWgEmmdUxJQB8p3nOLi+0323vDrPPl+U0yCGvh6taKi+jqhmgkH5Phukt9wOEh78ZsFh2kEnL2ZcPZTjLr6TOSw4kbT5zia5lokZN1AOed2AtiZ+XOXiKwFMHWkJ0YIIYQQUqzk5ECJSCOABQBeybx0g4i8KSL3ikhNnudGCCGEEFKUhN5AiUgVgIcB3Oic6wTwYwAzAMzH0BOqfz7AuEUiskxElqV67a9gE0IIIYSMNkJtoEQkjqHN08+cc48AgHNul3Mu5ZxLA/g3AKcFjXXOLXbOLXTOLYxW2N5xhBBCCCGjjawOlIgIgHsArHXO3bbf6/UZPwoAPgNgVbZzNYxvwT9dfd/e+La2WSanZHGtiiNjdWHHKy99zoz5fZ/eB1YuXWtymj97korfSXareMpSa9Dt+KQWbSdF9QYw1dZmr3OKPo+s0d9suv63zZg9Kf1krnq9Pn7uZ9eYMc/36mKbPQ12/jVRLWpLjRazT6mxQvvypF7LxEQt3sbabPHNwRp9nZJ2rxBiiZWlezvLVOwGPYk8YQtpok9L5K2pKpMS6/EaQDu/kGZ22TiW8AtG2p8z0gn9Vyfu5fQN2Pdc4onZvYMlJseXyP1Cmv5xAGhP6fUvi3gieoBsn63Ypn8cANJGNPcaEgcsbcQvpDmMhsP+OYLwJfKg6/iSuC+ihymwGEZWH46MbhoOD6Np8bAoJnG4mOZCSAjC/BbeWQC+COAtEXn/19C+A+AqEZkPwAHYAuCrIzJDQgghhJAiI8xv4b2A4J8Nnsj/dAghhBBCih9WIieEEEIIyZGCNhMeExnEOeWte+O/v+NLJmfSkldUvOVbH1Lxkgm6cTAAzH72OhXPSqw2OT2f7lTxLTsvVHH181vMmFO/1ariV/u1WxIZYxv4NizYoeK+++pVHK22bs+yfu19VW/Qrs8ppfqcAPCfO3Xhz8S0AZPjMzhRF+icX/muyVkO3UB5YKJ2YaTT/iZl/wzteZV5DpRUakcHAKTLu/U8Z2VXwq6tS+h1aQlwoKJ9vv+jzxsPcKD8YpuRfpNikAH9s0fE+1mkP2n/apV6z3GDHCi/CKZfbNP3mwAgMeg3E9Y5A0HNhLMU24xFbGvgbA2Hg0ymoIKcPtkaDgc1E7Y5h+4vhVJwQvlNR1iz2hDvOVTDYTpO5AiDT6AIIYQQQnKEGyhCCCGEkBzhBooQQgghJEcK6kC93TMBZ7z253vjqYuXmZzIzEYVf+GqpSpeOWDr00z7uX4bqTPnmpzbT/6pir/2yJdVfFzTS2bMDRP/qOKbt12iYne8bQn45WO0o/XT1eerOD3DNiB+vG2+iks271ZxQ6zcjFm1bYqKp0xtNTl+fam+en2euSVNZozEdTPkyom67pPr0vWzAKBvvHZsKnd53lSFdaDinQffu+/ptUVXa/o7VNw8aD2pSK92wbrSem6xhPVp/HpAsYRJMUi/Fjrioq+THAho4OsVCOobDGom7DtQ2etA9XsNhytieg2Cmgn7DpTvScWDmglnaTjsHwdsjSdrVmWv8xQJ4c7koz7TcM+R9nysvHhS+WpsfKT5WGHIS32swqzbqGo2TAx8AkUIIYQQkiPcQBFCCCGE5Ag3UIQQQgghOcINFCGEEEJIjhRUIo83Ceq/v094jcyebnLWX6uLMj4xYZ2KT/ijLpoJAMf+9nUVb/zeQpNzXoWWbxuW6jh27DQzZnZci8yvvKYF6+pTrAF4UcVWFf9s0zYVt15mBfdn35up4mm7NqjYF5QBILpZN+P94Jy3TM4mr1Bjz2R9noaATz9Spd/zceNbVDzQa5sJ99fqdaheryVmN9YK4SWd3tpF9Nw6eqw4Xz2gz7t7YKzJkT5dBbPLa8Yb7bNydMJp6T2ayC6QRgf0/COeuTqYDChe6eUkBgPkbk9o9wtpxsX+EoXfcLhedJPrRDpAVveKbSbhyfaBhTQPnpMKMGLDFNv0RXM/J6jZcNorkOpf2TQKRoiGwwHicNB58kGohsOEFBu8bxV8AkUIIYQQkiPcQBFCCCGE5EjWDZSIlInIqyLyhoisFpF/yLw+XUReEZGNIvILEbGNvQghhBBCjkDCOFD9AM5xznWLSBzACyLyJIC/AXC7c+4hEbkbwHUAfnzQM/X0QV5+c2/49n0LTMoPzvi5iu9oa1TxhAdtUcbIeN2M94pzXzQ5z3nFEctfWq/iPQFu0uakLho52TvtjnOsJ1IT1fNLdeomxq32MpAN2uVxSe36+AUxAWDMZh2fOWaDyXmt7zgV99brL7DHRaxnJNV6LieM1Q2HV1oFB4nx2h2JdfSpeLDaXife6TWDLdGeTn+P3Y+7lF7v5gFbSBMJ7UC1p/XnEeu1n1m/055LNEQhzYhXSDMq+mcRN2B/NolL9obDJV5xykRK5wQV0vQdpxKvSGZvujRgLgdvJuwfB2yhTL/YZjpAkIiJ70mZFFNI03eTwhS4zFaMM8x5QnlJebhOKALmknLD8LHyUlQyD+fIF8U0F3LUk/UJlBvi/Z1EPPOPA3AOgF9lXr8fwGUjMkNCCCGEkCIjlAMlIlERWQlgN4CnAbwDoN25vb++tA2A7WtCCCGEEHIEEmoD5ZxLOefmA2gAcBqAOWEvICKLRGSZiCxLoj/7AEIIIYSQIien38JzzrUDeBbAGQCqReR9caIBwPYDjFnsnFvonFsYh3UxCCGEEEJGG1klchGZCCDpnGsXkXIAnwTwTxjaSF0O4CEA1wD4dbZzpcZXov3i0/fGf/z4D0zOJE/C/sDdV6v42CdWmDFN12oZ/TsTl5ics5Zdq+LJXW+ruPlc+3TsX1s+ouLqV3eoePqNWhAHgLUDutBkpEwXvKyeqwtTAgAeHq/HjNFy9JqkLUQ5bosWzeeX7jA5NzefouLE5AAD3CNVW6XiueW6EOhKNJgxA7VaFJZOLb0PNI4zY0o9iVzKPdG8O+DW9OTi5kSVTfGKbban9P0UTdg1SHjnjfX7UrOVd6PZHqYGSOQR7+eVgaBCmp4kmzCFNAMk+LQnmntFMhODtpCmf54Br0hmacSuky+am0KaAYavL3cHadAxObgcHSSIp+D9EoJXbNM/DmSXxMPI36Ec5jzJ6AU5R74I8Z5dtvlSECejjDC/hVcP4H4RiWLoidUvnXOPi8gaAA+JyC0AXgdwzwjOkxBCCCGkaMi6gXLOvQnA1Btwzm3CkA9FCCGEEHJUwUrkhBBCCCE5Is5vqDmSFxNpBvAugAkA9hTswkcXXNuRhes7cnBtRw6u7cjBtR05imFtj3XOTQw6UNAN1N6Liixzzi0s+IWPAri2IwvXd+Tg2o4cXNuRg2s7chT72vIrPEIIIYSQHOEGihBCCCEkRw7XBmrxYbru0QDXdmTh+o4cXNuRg2s7cnBtR46iXtvD4kARQgghhIxm+BUeIYQQQkiOcANFCCGEEJIj3EARQgghhOQIN1CEEEIIITnCDRQhhBBCSI78fwhP66JWobZ1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "# ax.matshow(PositionalEmbedding(128, 32)(torch.Size([1, 32, 128]))[0,:,:].numpy())\n",
    "ax.matshow(positional_encoding_matrix(10, 128, 32)[0,:,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31f637d7",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1631108867354,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "f8a4959f"
   },
   "outputs": [],
   "source": [
    "class EncoderComponent(nn.Module):\n",
    "    '''\n",
    "    The individual component of encoder stack. \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, embedding_size, n_heads, projection_size_qk, projection_size_v, n_hidden,dropout_fraction):\n",
    "        super(EncoderComponent, self).__init__()\n",
    "        self.mha = MultiHeadAttention(n_heads, projection_size_qk, projection_size_v, \n",
    "                                      embedding_size)\n",
    "        self.fc1 = nn.Linear(embedding_size, n_hidden)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(n_hidden, embedding_size)\n",
    "        self.layernorm1 = nn.LayerNorm(embedding_size)\n",
    "        self.layernorm2 = nn.LayerNorm(embedding_size)\n",
    "        self.dropout1 = nn.Dropout(dropout_fraction)\n",
    "        self.dropout2 = nn.Dropout(dropout_fraction)\n",
    "        self.dropout3 = nn.Dropout(dropout_fraction)\n",
    "        \n",
    "    def forward(self, inputs, pad_mask=None):\n",
    "        mha0, aw = self.mha(inputs, inputs, inputs, pad_mask)\n",
    "        mha = self.layernorm1(self.dropout1(mha0) + inputs)\n",
    "        out = self.layernorm2(self.dropout2(self.fc2(self.dropout3(self.relu(self.fc1(mha))))) + mha)\n",
    "        return out, aw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26ad6486",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1631108867355,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "vfmCSUTT_ADr"
   },
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    '''\n",
    "    The encoder stack. \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, batch_size, vocab_size_in, embedding_size, \n",
    "                 max_in_seq_len, n_heads, projection_size_qk, projection_size_v,n_hidden, n_enc_layers, dropout_fraction):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size_in,embedding_size, padding_idx=pad_indx)\n",
    "        self.pos_encoding_matrix = positional_encoding_matrix(batch_size,embedding_size, max_in_seq_len)\n",
    "        self.encoder_stack = nn.ModuleList([EncoderComponent(embedding_size, n_heads, \n",
    "                                               projection_size_qk, projection_size_v, n_hidden,dropout_fraction) for _ in torch.arange(n_enc_layers)])\n",
    "        \n",
    "        \n",
    "        self.dropout1 = nn.Dropout(dropout_fraction)\n",
    "        self.sqrt_embedding_size  = embedding_size**(0.5)\n",
    "    def forward(self, inputs, pad_mask=None, return_attention_weights=False):\n",
    "        \n",
    "\n",
    "        emb = self.embedding(inputs)\n",
    "        pos_enc = self.pos_encoding_matrix[:inputs.shape[0], :inputs.shape[1],:].to(inputs.device)\n",
    "        x = self.dropout1(emb*self.sqrt_embedding_size + pos_enc)\n",
    "        if not return_attention_weights:\n",
    "            for encoder_component in self.encoder_stack:\n",
    "                x,_ = encoder_component(x, pad_mask)\n",
    "            return x, None\n",
    "        else:\n",
    "            aw_list=[]\n",
    "            for encoder_component in self.encoder_stack:\n",
    "                x,aw = encoder_component(x, pad_mask)\n",
    "                aw_list.append(aw)\n",
    "            return x, aw_list\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e8ad483",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1631108867902,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "dmp8xuu3_GP_"
   },
   "outputs": [],
   "source": [
    "class DecoderComponent(nn.Module):\n",
    "    '''\n",
    "    The individual component of decoder stack. \n",
    "    '''\n",
    "    def __init__(self, embedding_size, n_heads, projection_size_qk, projection_size_v, n_hidden, dropout_fraction):\n",
    "        super(DecoderComponent, self).__init__()\n",
    "        self.mha1 = MultiHeadAttention(n_heads, projection_size_qk, projection_size_v, embedding_size)\n",
    "        self.mha2 = MultiHeadAttention(n_heads, projection_size_qk, projection_size_v, embedding_size)\n",
    "        self.fc1 = nn.Linear(embedding_size, n_hidden)\n",
    "        self.relu = nn.GELU()#nn.ReLU()\n",
    "        self.fc2 = nn.Linear(n_hidden, embedding_size)\n",
    "        self.layernorm1 = nn.LayerNorm(embedding_size)\n",
    "        self.layernorm2 = nn.LayerNorm(embedding_size)\n",
    "        self.dropout1 = nn.Dropout(dropout_fraction)\n",
    "        self.dropout2 = nn.Dropout(dropout_fraction)\n",
    "        self.dropout3 = nn.Dropout(dropout_fraction)\n",
    "        self.dropout4 = nn.Dropout(dropout_fraction)\n",
    "        \n",
    "    def forward(self, outputs, encoder_outputs, mask, inp_pad_mask):\n",
    "        mha1, aw1 = self.mha1(outputs, outputs, outputs, mask)\n",
    "        mha1 = self.layernorm1(self.dropout1(mha1) + outputs)\n",
    "        \n",
    "        mha2, aw2 = self.mha2(mha1, encoder_outputs, encoder_outputs, inp_pad_mask)\n",
    "        mha2 = self.layernorm1(self.dropout2(mha2) + mha1)\n",
    "        out = self.layernorm2(self.dropout3(self.fc2(self.dropout4(self.relu(self.fc1(mha2))))) + mha2)\n",
    "        return out, aw1, aw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cb5de8f",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1631108868376,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "2ad82e69"
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    '''\n",
    "    The decoder stack. \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, batch_size, vocab_size_out, embedding_size, max_out_seq_len, n_heads, projection_size_qk, projection_size_v, n_hidden, n_dec_layers, dropout_fraction):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size_out,embedding_size, padding_idx=pad_indx)\n",
    "        self.pos_encoding_matrix = positional_encoding_matrix(batch_size,embedding_size, max_out_seq_len)\n",
    "        self.decoder_stack = nn.ModuleList([DecoderComponent(embedding_size, n_heads, \n",
    "                                               projection_size_qk, projection_size_v, n_hidden, dropout_fraction) for _ in torch.arange(n_dec_layers)])\n",
    "        \n",
    "        self.linear = nn.Linear(n_hidden, vocab_size_out)\n",
    "        self.lsf = nn.LogSoftmax(dim=-1)\n",
    "        self.dropout1 = nn.Dropout(dropout_fraction)\n",
    "        self.sqrt_embedding_size  = embedding_size**(0.5)\n",
    "        \n",
    "    def forward(self, outputs, encoder_outputs, mask,inp_pad_mask, return_attention_weights = False):\n",
    "        emb = self.embedding(outputs)\n",
    "        pos_dec = self.pos_encoding_matrix[:outputs.shape[0], :outputs.shape[1],:].to(outputs.device)\n",
    "        x = self.dropout1(emb*self.sqrt_embedding_size + pos_dec)\n",
    "        if not return_attention_weights:\n",
    "            for decoder_component in self.decoder_stack:\n",
    "                x,_,_ = decoder_component(x,encoder_outputs,  mask, inp_pad_mask)\n",
    "            return self.lsf(self.linear(x)), None, None\n",
    "        else:\n",
    "            aw_list1=[]\n",
    "            aw_list2=[]\n",
    "            for decoder_component in self.decoder_stack:\n",
    "                x,aw1, aw2 = decoder_component(x,encoder_outputs,  mask, inp_pad_mask)\n",
    "                aw_list1.append(aw1)\n",
    "                aw_list2.append(aw2)\n",
    "            return self.lsf(self.linear(x)), aw_list1, aw_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5dfefe59",
   "metadata": {
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1631108869339,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "5d9bfb12"
   },
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    '''\n",
    "    The transformer model as described in \"Attention is all you need\"\n",
    "    '''\n",
    "    def __init__(self, batch_size, vocab_size_in, vocab_size_out, embedding_size, max_in_seq_len, max_out_seq_len, n_heads,\n",
    "                 projection_size_qk, projection_size_v,n_hidden, n_enc_layers, n_dec_layers, dropout_fraction):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.encoder = EncoderBlock(batch_size, vocab_size_in, embedding_size, \n",
    "                 max_in_seq_len, n_heads, projection_size_qk, projection_size_v,n_hidden, n_enc_layers,dropout_fraction)\n",
    "            \n",
    "        self.decoder = DecoderBlock(batch_size, vocab_size_out, embedding_size, max_out_seq_len, n_heads,\n",
    "                                    projection_size_qk, projection_size_v, n_hidden, n_dec_layers,dropout_fraction)\n",
    "        self.vocab_size_out = vocab_size_out\n",
    "        \n",
    "        for param in self.parameters():\n",
    "            if param.requires_grad:\n",
    "                if param.dim()>=2:\n",
    "                    torch.nn.init.xavier_uniform_(param)  \n",
    "#                 else:\n",
    "#                     torch.nn.init.uniform_(param)  \n",
    "            \n",
    "    def forward(self, inputs, outputs, return_attention_weights=False):\n",
    "        \n",
    "        inp_pad_mask = ((inputs.detach()==pad_indx) ).unsqueeze(1)\n",
    "        encoder_outputs, aw_enc = self.encoder(inputs,inp_pad_mask)\n",
    "        \n",
    "        \n",
    "        output_mask = torch.tril(torch.ones((outputs.shape[1], outputs.shape[1]),device=outputs.device)).bool() # mask such that the decoder doesn't see subsequent output tokens\n",
    "        output_mask= ~output_mask.unsqueeze(0)\n",
    "        \n",
    "        out, aw_list1, aw_list2 = self.decoder(outputs, encoder_outputs, output_mask, inp_pad_mask, return_attention_weights)\n",
    "        \n",
    "        return out, aw_enc, aw_list1, aw_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dc3f12",
   "metadata": {
    "id": "Bm3punVCP7EI"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9b178cf",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1631108873216,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "Dt5tl_tYjBq-"
   },
   "outputs": [],
   "source": [
    "# label smoothing + NLLLoss\n",
    "class LabelSmoothingAndNLLLoss(nn.Module):\n",
    "    def __init__(self, alpha =0.1, reduction = 'mean', ignore_index = -100):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, log_pred_probs, true_targets):\n",
    "    \n",
    "        l_nll = F.nll_loss(log_pred_probs, true_targets, reduction=self.reduction, ignore_index=self.ignore_index)\n",
    "        log_pred_probs = log_pred_probs.masked_fill((true_targets == self.ignore_index).unsqueeze(1), 0 ) # ignoring ignore_indx\n",
    "        \n",
    "        # reduction\n",
    "        if self.reduction == 'mean':\n",
    "            l_other = -log_pred_probs.mean()  \n",
    "        elif self.reduction == 'sum':\n",
    "            l_other = -log_pred_probs.sum()\n",
    "        \n",
    "        return (1.0-self.alpha)*l_nll + (self.alpha/log_pred_probs.shape[-1])* l_other\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d59df19",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1631108874471,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "JOZImoaTH62V"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader_valid, loss_function):\n",
    "    # Eval on validation data\n",
    "    model.eval()\n",
    "    loss_val = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_sentences = []\n",
    "        true_pred_sentences = []\n",
    "        for batch, a in enumerate(dataloader_valid):\n",
    "            inputs = a[0]\n",
    "            targets = a[1]\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # compute predictions\n",
    "            pred,*_ = model(inputs, targets[:,:-1])\n",
    "            \n",
    "            for row in targets:\n",
    "                true_pred_sentences.append([[v_t[token]  for token in row.tolist() if token is not pad_indx]])\n",
    "            \n",
    "            for row in torch.argmax(pred, dim=-1):\n",
    "                pred_sentences.append([v_t[token]  for token in row.tolist() if token is not pad_indx])\n",
    "            \n",
    "            # compute loss\n",
    "            loss = loss_function(pred.view(-1,pred.shape[-1]), targets[:,1:].long().view(-1))\n",
    "\n",
    "            # loss\n",
    "            loss_val += loss.item()\n",
    "\n",
    "        loss_val = loss_val/len(dataloader_valid)\n",
    "        bleu_score = torchtext.data.metrics.bleu_score(pred_sentences,true_pred_sentences)\n",
    "\n",
    "    return loss_val, bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73cec32f",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1631108875841,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "adEwalmpIJiT"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader_train,loss_function, optimizer, scheduler, clip_norm):\n",
    "    model.train()\n",
    "    \n",
    "    loss_accumulated = 0\n",
    "    for batch, (inputs, targets) in tqdm(enumerate(dataloader_train), total=len(dataloader_train)):\n",
    "\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred,*_  = model(inputs, targets[:,:-1]) \n",
    "\n",
    "        # compute loss\n",
    "        loss = loss_function(pred.view(-1,pred.shape[-1]), targets[:,1:].long().view(-1))\n",
    "\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_norm)\n",
    "        # torch.nn.utils.clip_grad_value_(model.parameters(), CLIP_VAL)\n",
    "\n",
    "        # update params\n",
    "        optimizer.step()\n",
    "\n",
    "        # lr scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        loss_accumulated += loss.item()\n",
    "    loss_accumulated = loss_accumulated/len(dataloader_train)\n",
    "\n",
    "    return loss_accumulated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ada8d6",
   "metadata": {
    "id": "vdmvjnB4tNAC"
   },
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf7c75ba",
   "metadata": {
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1631108999447,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "8AO152WPap93"
   },
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    'batch_size':64,\n",
    "    'vocab_size_in':len(vocab_src),\n",
    "    'vocab_size_out':len(vocab_trg),\n",
    "    'embedding_size':512,\n",
    "    'max_in_seq_len':200, # need only for positional encoding...any number greater than the actual max_length should do\n",
    "    'max_out_seq_len':250, \n",
    "    'n_heads':8,\n",
    "    'projection_size_qk':64,\n",
    "    'projection_size_v':64,\n",
    "    'n_enc_layers':3,\n",
    "    'n_dec_layers':3,\n",
    "    'n_hidden':512,\n",
    "    'dropout_fraction':0.1,\n",
    "    'num_epochs': 50,\n",
    "    'learning_rate':0.0005,\n",
    "    'clip_norm': 0.5,\n",
    "    'label_smoothing_alpha': 0.1,\n",
    "    'dataset': 'Multi30k_de_en',\n",
    "    'model_type': 'Transformer'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88200b64",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1631108878576,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "tEDkxj_smMme"
   },
   "outputs": [],
   "source": [
    "def model_pipeline(config= config_dict):\n",
    "\n",
    "    with wandb.init(project=\"NMT\", config=config_dict) as run:\n",
    "        \n",
    "        config = wandb.config\n",
    "\n",
    "        # generate dataloaders\n",
    "        BATCH_SIZE = config.batch_size\n",
    "        SHUFFLE = True\n",
    "        DROP_LAST = False\n",
    "        dataloader_train  = torch.utils.data.DataLoader(dataset_train, shuffle=SHUFFLE, batch_size=BATCH_SIZE, drop_last=DROP_LAST, collate_fn=collate_by_padding, num_workers=2, pin_memory=True)\n",
    "        dataloader_valid  = torch.utils.data.DataLoader(dataset_valid, shuffle=SHUFFLE, batch_size=BATCH_SIZE, drop_last=DROP_LAST, collate_fn=collate_by_padding, num_workers=2, pin_memory=True)\n",
    "\n",
    "        # build model\n",
    "        \n",
    "        model = TransformerModel(config.batch_size, config.vocab_size_in, config.vocab_size_out, config.embedding_size,config.max_in_seq_len,\n",
    "                                 config.max_out_seq_len, config.n_heads, config.projection_size_qk, \n",
    "                                 config.projection_size_v,config.n_hidden, config.n_enc_layers,\n",
    "                                 config.n_dec_layers, config.dropout_fraction)\n",
    "\n",
    "        # loss function\n",
    "        # loss_function = nn.NLLLoss()\n",
    "        loss_function = LabelSmoothingAndNLLLoss(alpha = config.label_smoothing_alpha)\n",
    "\n",
    "\n",
    "        # optimizer \n",
    "        # optimizer = torch.optim.Adam(model.parameters(),lr=config.learning_rate)\n",
    "        optimizer= torch.optim.Adam(model.parameters(), lr=config.learning_rate, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "        # lr scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=config.learning_rate, \n",
    "                                                        steps_per_epoch=len(dataloader_train), \n",
    "                                                        epochs=config.num_epochs, \n",
    "                                                        cycle_momentum=True, \n",
    "                                                        anneal_strategy = 'linear', \n",
    "                                                        three_phase=True, \n",
    "                                                        pct_start=0.4,\n",
    "                                                        div_factor=10.0,\n",
    "                                                        final_div_factor = 1000.0\n",
    "                                                        )\n",
    "        \n",
    "        # send model to device\n",
    "        model = model.to(device)\n",
    "\n",
    "        # free memory\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # suffix for checkpoints\n",
    "        suffix = '_'.join([config.model_type, config.dataset, str(config.embedding_size) , \n",
    "                           str(config.batch_size),datetime.now().strftime('%b%d_%H-%M-%S') ])\n",
    "        \n",
    "        # wandb watch\n",
    "        wandb.watch(model, loss_function, log=\"all\", log_freq=10, log_graph=False)\n",
    "\n",
    "        # train and eval\n",
    "        min_valid_loss_until_now = 1000\n",
    "        max_valid_bleu_until_now = -1000\n",
    "        patience = config.early_stopping_patience\n",
    "        epochs_since_last_val_best = 0\n",
    "        for epoch in tqdm(range(config.num_epochs)):\n",
    "            # train\n",
    "            loss_train_teacher_forced = train_model(model, dataloader_train, loss_function,optimizer,scheduler, config.clip_norm)\n",
    "\n",
    "            # eval\n",
    "            loss_val, bleu_val = eval_model(model, dataloader_valid, loss_function)\n",
    "            # loss_train, bleu_train = eval_model(model, dataloader_train, loss_function)\n",
    "\n",
    "            wandb.log({\"epoch\": epoch, \n",
    "                    # \"loss_train\": loss_train, \n",
    "                    'loss_val': loss_val,\n",
    "                    'loss_train_teacher_forced': loss_train_teacher_forced,\n",
    "                    # 'bleu_train':bleu_train,\n",
    "                    'bleu_val': bleu_val}, step=epoch)\n",
    "            \n",
    "            # # checkpoint\n",
    "            \n",
    "            torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        # 'loss_train': loss_train,\n",
    "                        'loss_train_teacher_forced': loss_train_teacher_forced,\n",
    "                        'loss_val':loss_val,\n",
    "                        'bleu_val': bleu_val,\n",
    "                        # 'bleu_train':bleu_train,\n",
    "                        'config': config_dict,\n",
    "                        }, 'saved_models/'+suffix+'_latest_train.pth')\n",
    "\n",
    "            if min_valid_loss_until_now > loss_val:\n",
    "                min_valid_loss_until_now = loss_val\n",
    "                torch.save({\n",
    "                            'epoch': epoch,\n",
    "                            'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            # 'loss_train': loss_train,\n",
    "                            'loss_train_teacher_forced': loss_train_teacher_forced,\n",
    "                            'loss_val':loss_val,\n",
    "                            'bleu_val': bleu_val,\n",
    "                            # 'bleu_train':bleu_train,\n",
    "                            'config': config_dict,\n",
    "                            }, 'saved_models/'+suffix+'_best_val_loss.pth')\n",
    "            \n",
    "            if max_valid_bleu_until_now < bleu_val:\n",
    "                max_valid_bleu_until_now = bleu_val\n",
    "                torch.save({\n",
    "                            'epoch': epoch,\n",
    "                            'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            # 'loss_train': loss_train,\n",
    "                            'loss_train_teacher_forced': loss_train_teacher_forced,\n",
    "                            'loss_val':loss_val,\n",
    "                            'bleu_val': bleu_val,\n",
    "                            # 'bleu_train':bleu_train,\n",
    "                            'config': config_dict,\n",
    "                            }, 'saved_models/'+suffix+'_best_val_bleu.pth')\n",
    "\n",
    "                epochs_since_last_val_best = 0\n",
    "            else:\n",
    "                epochs_since_last_val_best += 1\n",
    "\n",
    "            # Early stopping\n",
    "\n",
    "            if epochs_since_last_val_best >= patience :\n",
    "                print('Early stopping triggered.')\n",
    "                break\n",
    "\n",
    "    return model, dataloader_train, dataloader_valid, suffix\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793333e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "513aafa9f82f4502b15512f7f5a40fff",
      "aa8fa81eb2734f17b23119afca373bb3",
      "14319f163ab54ade8392ca4c712b60fd",
      "296585981f3a4bd09621dc256fc8bcac",
      "ee04f398b24048ac970e8a8709294639",
      "9584793e7c1141aeb02794a31ff65871",
      "39772d6f341e41968a45bf9ac4abc2ac",
      "507a80612ebd4cf4acd88196b6071abb",
      "e9f241d6a41d468d88764db4564aa42c",
      "8b66b6d9dfa647efb84d49440439a813",
      "cf8d9786e0a041fba009f5f0c9c5f48d",
      "da4d394eeea24f5caefb0e2de8ba94b7",
      "b2bce103e6424fa7ae305ab7c9547711",
      "0017d7a1cb96431f8dfef8b98dd215aa",
      "2fe2c43860f24043b50f47d024986eac",
      "df507601c2c740aea58aee776c1b226e",
      "736be68bb3e2496e96d1850d0328c852",
      "9a83599fae43474e9050dd50c031b14c",
      "99a2a21787964cf9a4db35fdfdee7eb3",
      "612c712f76c24e89b95d94fa714b03fa",
      "74a389b8d7ce47018dd0764022e2df7b",
      "19aad448ab324d5390cf5abc7999f4b9"
     ]
    },
    "executionInfo": {
     "elapsed": 2221589,
     "status": "ok",
     "timestamp": 1631011550426,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "zWmB_7w5mMme",
    "outputId": "f8e29c48-358d-4978-cb00-81f97ccb3153"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">magic-wind-141</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/skml/NMT\" target=\"_blank\">https://wandb.ai/skml/NMT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/skml/NMT/runs/1097a1lt\" target=\"_blank\">https://wandb.ai/skml/NMT/runs/1097a1lt</a><br/>\n",
       "                Run data is saved locally in <code>/content/drive/My Drive/PyTorch/wandb/run-20210907_094236-1097a1lt</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513aafa9f82f4502b15512f7f5a40fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8fa81eb2734f17b23119afca373bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14319f163ab54ade8392ca4c712b60fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296585981f3a4bd09621dc256fc8bcac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee04f398b24048ac970e8a8709294639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9584793e7c1141aeb02794a31ff65871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39772d6f341e41968a45bf9ac4abc2ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507a80612ebd4cf4acd88196b6071abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f241d6a41d468d88764db4564aa42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b66b6d9dfa647efb84d49440439a813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8d9786e0a041fba009f5f0c9c5f48d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4d394eeea24f5caefb0e2de8ba94b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bce103e6424fa7ae305ab7c9547711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0017d7a1cb96431f8dfef8b98dd215aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe2c43860f24043b50f47d024986eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df507601c2c740aea58aee776c1b226e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736be68bb3e2496e96d1850d0328c852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a83599fae43474e9050dd50c031b14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a2a21787964cf9a4db35fdfdee7eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612c712f76c24e89b95d94fa714b03fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a389b8d7ce47018dd0764022e2df7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 581<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19aad448ab324d5390cf5abc7999f4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/content/drive/My Drive/PyTorch/wandb/run-20210907_094236-1097a1lt/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/content/drive/My Drive/PyTorch/wandb/run-20210907_094236-1097a1lt/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>19</td></tr><tr><td>loss_val</td><td>2.05415</td></tr><tr><td>loss_train_teacher_forced</td><td>0.26587</td></tr><tr><td>bleu_val</td><td>0.10229</td></tr><tr><td>_runtime</td><td>3788</td></tr><tr><td>_timestamp</td><td>1631011545</td></tr><tr><td>_step</td><td>19</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss_val</td><td>█▅▃▂▂▂▁▁▁▂▃▃▄▄▅▅▆▆▆▆</td></tr><tr><td>loss_train_teacher_forced</td><td>█▆▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>bleu_val</td><td>▁▃▄▅▅▆▆▆▇▇██████████</td></tr><tr><td>_runtime</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇███</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">magic-wind-141</strong>: <a href=\"https://wandb.ai/skml/NMT/runs/1097a1lt\" target=\"_blank\">https://wandb.ai/skml/NMT/runs/1097a1lt</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, dataloader_train, dataloader_valid, suffix = model_pipeline(config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720dc014",
   "metadata": {
    "id": "wMHcz9fv-Hqp"
   },
   "source": [
    "# Some translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "064be869",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4926,
     "status": "ok",
     "timestamp": 1631109103486,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "3_pWROL4-Hqp",
    "outputId": "991eac6f-66ea-4c4c-8de1-56adba287b56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "config = namedtuple('obj', config_dict.keys())(*config_dict.values())\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, shuffle=False, batch_size=len(dataset_test), drop_last=False, collate_fn=collate_by_padding)\n",
    "model = TransformerModel(config.batch_size, config.vocab_size_in, config.vocab_size_out, config.embedding_size,config.max_in_seq_len,\n",
    "                                 config.max_out_seq_len, config.n_heads, config.projection_size_qk, \n",
    "                                 config.projection_size_v,config.n_hidden, config.n_enc_layers,\n",
    "                                 config.n_dec_layers, config.dropout_fraction)\n",
    "saved_model = torch.load('saved_models/Transformer_Multi30k_de_en_512_64_Sep07_07-47-50_best_val_bleu.pth',map_location='cpu')\n",
    "# saved_model = torch.load('saved_models/'+suffix+'_best_val_bleu.pth',map_location='cpu')\n",
    "model.load_state_dict(saved_model['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "63d25755",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1631109874350,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "J7CcWoXe-Hqp"
   },
   "outputs": [],
   "source": [
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "inputs, targets = next(iter(dataloader_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "210cb576",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1631109874673,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "nge-NwEomMmj"
   },
   "outputs": [],
   "source": [
    "def translate(model, inputs, return_attention_weights=False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inp_pad_mask = ((inputs.detach()==pad_indx) ).unsqueeze(1)\n",
    "        encoder_outputs, aw_enc = model.encoder(inputs,inp_pad_mask)\n",
    "\n",
    "        pred = torch.tensor([[2]])\n",
    "        # output_mask = None\n",
    "        output_mask = torch.tril(torch.ones((pred.shape[1], pred.shape[1]),device=pred.device)).bool() # mask such that the decoder doesn't see subsequent output tokens\n",
    "        output_mask= ~output_mask.unsqueeze(0)    \n",
    "        \n",
    "        out,*_ = model.decoder(pred, encoder_outputs, output_mask, inp_pad_mask, return_attention_weights)\n",
    "    \n",
    "        pred = torch.cat((pred,out[:,-1,:].argmax(-1).unsqueeze(1)), dim=-1)\n",
    "    \n",
    "        for i in range(50):\n",
    "            out,*_ = model.decoder(pred, encoder_outputs, output_mask, inp_pad_mask, return_attention_weights)\n",
    "            pred = torch.cat((pred,out[:,-1,:].argmax(-1).unsqueeze(1)), dim=-1)\n",
    "            output_mask = torch.tril(torch.ones((pred.shape[1], pred.shape[1]),device=pred.device)).bool() # mask such that the decoder doesn't see subsequent output tokens\n",
    "            output_mask= ~output_mask.unsqueeze(0)\n",
    "        \n",
    "    return pred\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eb9a85b0",
   "metadata": {
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1631109876679,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "07vPkAAnrrRI"
   },
   "outputs": [],
   "source": [
    "def beamSearch(model, inputs, beam_width=2, max_len = 50, return_attention_weights=False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inp_pad_mask = ((inputs.detach()==pad_indx) ).unsqueeze(1)\n",
    "        encoder_outputs, aw_enc = model.encoder(inputs,inp_pad_mask)\n",
    "\n",
    "        pred = torch.tensor([[2]]) # <bos> token\n",
    "        # output_mask = None\n",
    "        output_mask = torch.tril(torch.ones((pred.shape[1], pred.shape[1]),device=pred.device)).bool() # mask such that the decoder doesn't see subsequent output tokens\n",
    "        output_mask= ~output_mask.unsqueeze(0)\n",
    "        \n",
    "        out,*_ = model.decoder(pred, encoder_outputs, output_mask, inp_pad_mask, return_attention_weights)\n",
    "\n",
    "        # pred = torch.cat((pred,out[:,-1,:].argmax(-1).unsqueeze(1)), dim=-1)\n",
    "        topk = torch.topk(out[:,-1,:], k=beam_width, dim=-1)\n",
    "\n",
    "        candidate_tokens = topk.indices.squeeze(0)\n",
    "        candidate_token_log_probs = topk.values.squeeze(0)\n",
    "\n",
    "        to_do_list = []\n",
    "        [to_do_list.append([candidate_tokens[i].view(1,1), candidate_token_log_probs[i]]) for i in range(beam_width)]\n",
    "        done_list = []\n",
    "\n",
    "        while to_do_list: # not empty\n",
    "            to_do_list1 = to_do_list.copy()\n",
    "            for pred, lp in to_do_list1:\n",
    "                if torch.numel(pred) > max_len or pred[-1,-1].item() == 3: #(eos token )\n",
    "                    done_list.append([pred, lp])\n",
    "                    to_do_list.remove([pred, lp])\n",
    "                else:\n",
    "                    to_do_list.remove([pred, lp])\n",
    "                    output_mask = torch.tril(torch.ones((pred.shape[1], pred.shape[1]),device=pred.device)).bool() # mask such that the decoder doesn't see subsequent output tokens\n",
    "                    output_mask= ~output_mask.unsqueeze(0)\n",
    "                    out,*_ = model.decoder(pred, encoder_outputs, output_mask, inp_pad_mask, return_attention_weights)\n",
    "                    topk = torch.topk(out[:,-1,:], k=beam_width, dim=-1)\n",
    "\n",
    "                    candidate_tokens = topk.indices.squeeze(0)\n",
    "                    candidate_token_log_probs = topk.values.squeeze(0)\n",
    "\n",
    "                    [to_do_list.append([torch.cat((pred,candidate_tokens[i].view(1,1)), dim=-1), lp+candidate_token_log_probs[i]]) for i in range(beam_width)]\n",
    "            to_do_list = sorted(to_do_list, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "            \n",
    "        done_list = sorted(done_list, key=lambda x: x[1], reverse=True)[:beam_width]    \n",
    "    return done_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "41ef97c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3544,
     "status": "ok",
     "timestamp": 1631109880221,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "_Js0JEcvmMmj",
    "outputId": "19a500b9-adc6-4498-cd55-037d0c7230b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind: 190 \n",
      "\n",
      "Source: \n",
      "Eine Frau mit braunen Haaren sitzt auf einer Bank vor einem Café. <eos>\n",
      "\n",
      "Original Translation: \n",
      "<bos> A woman with brown hair sitting on a bench outside a cafe. <eos>\n",
      "\n",
      "Greedy translation: \n",
      "<bos> A woman with brown hair is sitting on a bench in front of a cafe. <eos>\n",
      "\n",
      "Model translation (Beam Search): 0\n",
      "A woman with brown hair is sitting on a bench in front of a cafe. <eos>\n",
      "\n",
      "Model translation (Beam Search): 1\n",
      "A woman with brown hair is sitting on a bench outside a cafe. <eos>\n",
      "\n",
      " -------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1):\n",
    "    ind = torch.randint(low=0, high=len(inputs), size=(1,)).item()\n",
    "    print(f'ind: {ind} \\n')\n",
    "    src = ' '.join([v_s[token]  for token in inputs[ind,:].tolist() if token is not pad_indx])\n",
    "    print('Source: \\n'+ src)\n",
    "    print('\\nOriginal Translation: \\n'+ ' '.join([v_t[token] for token in targets[ind,:].tolist() if token is not pad_indx]))\n",
    "    print('\\nGreedy translation: \\n'+\n",
    "    ' '.join([v_t[token] for token in translate(model,inputs[ind:ind+1,:]).squeeze().tolist() if token is not pad_indx]))\n",
    "    p = beamSearch(model, inputs[ind:ind+1,:], beam_width=2, max_len=50)\n",
    "    for i in range(len(p)):\n",
    "        print(f'\\nModel translation (Beam Search): {i}\\n'+\n",
    "            ' '.join([v_t[token] for token in p[i][0].squeeze().tolist() if token is not pad_indx]))\n",
    "    print('\\n -------------------------------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d771e615",
   "metadata": {
    "executionInfo": {
     "elapsed": 440,
     "status": "ok",
     "timestamp": 1631109651965,
     "user": {
      "displayName": "Sasi Kattamanchi",
      "photoUrl": "",
      "userId": "06124919951785490930"
     },
     "user_tz": -330
    },
    "id": "NZsHkcRB3ZG6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d773ec9d",
   "metadata": {
    "id": "s3IcTxkRrpdy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NMT_Transformer_de.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
